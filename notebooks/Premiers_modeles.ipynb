{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lib_mrq</th>\n",
       "      <th>lib_mod_doss</th>\n",
       "      <th>lib_mod</th>\n",
       "      <th>dscom</th>\n",
       "      <th>hybride</th>\n",
       "      <th>puiss_admin_98</th>\n",
       "      <th>puiss_max</th>\n",
       "      <th>conso_urb</th>\n",
       "      <th>conso_exurb</th>\n",
       "      <th>conso_mixte</th>\n",
       "      <th>...</th>\n",
       "      <th>ptcl</th>\n",
       "      <th>masse_ordma_min</th>\n",
       "      <th>masse_ordma_max</th>\n",
       "      <th>champ_v9</th>\n",
       "      <th>Carrosserie</th>\n",
       "      <th>gamme</th>\n",
       "      <th>carburant</th>\n",
       "      <th>typ_boite</th>\n",
       "      <th>nb_rapp</th>\n",
       "      <th>etiquette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALFA-ROMEO</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159 1750 Tbi (200ch)</td>\n",
       "      <td>non</td>\n",
       "      <td>12</td>\n",
       "      <td>147.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1505</td>\n",
       "      <td>1505</td>\n",
       "      <td>715/2007*692/2008EURO5</td>\n",
       "      <td>BERLINE</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>Essence</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALFA-ROMEO</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159 1750 Tbi (200ch)</td>\n",
       "      <td>non</td>\n",
       "      <td>12</td>\n",
       "      <td>147.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1555</td>\n",
       "      <td>1555</td>\n",
       "      <td>715/2007*692/2008EURO5</td>\n",
       "      <td>BERLINE</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>Essence</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALFA-ROMEO</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159 2.0 JTDm (136ch)</td>\n",
       "      <td>non</td>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>715/2007*692/2008EURO5</td>\n",
       "      <td>BERLINE</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>Gazoil</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALFA-ROMEO</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159 2.0 JTDm (136ch)</td>\n",
       "      <td>non</td>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>715/2007*692/2008EURO5</td>\n",
       "      <td>BERLINE</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>Gazoil</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALFA-ROMEO</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159 2.0 JTDm (170ch)</td>\n",
       "      <td>non</td>\n",
       "      <td>9</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>715/2007*692/2008EURO5</td>\n",
       "      <td>BERLINE</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>Gazoil</td>\n",
       "      <td>Manuelle</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lib_mrq lib_mod_doss lib_mod                 dscom hybride  \\\n",
       "0  ALFA-ROMEO          159     159  159 1750 Tbi (200ch)     non   \n",
       "1  ALFA-ROMEO          159     159  159 1750 Tbi (200ch)     non   \n",
       "2  ALFA-ROMEO          159     159  159 2.0 JTDm (136ch)     non   \n",
       "3  ALFA-ROMEO          159     159  159 2.0 JTDm (136ch)     non   \n",
       "4  ALFA-ROMEO          159     159  159 2.0 JTDm (170ch)     non   \n",
       "\n",
       "   puiss_admin_98  puiss_max  conso_urb  conso_exurb  conso_mixte  ...   ptcl  \\\n",
       "0              12      147.0       11.3          5.8          7.8  ...  0.002   \n",
       "1              12      147.0       11.5          6.0          8.0  ...  0.002   \n",
       "2               7      100.0        6.6          4.2          5.1  ...  0.001   \n",
       "3               7      100.0        6.6          4.2          5.1  ...  0.001   \n",
       "4               9      125.0        6.9          4.3          5.3  ...  0.001   \n",
       "\n",
       "   masse_ordma_min  masse_ordma_max                champ_v9  Carrosserie  \\\n",
       "0             1505             1505  715/2007*692/2008EURO5      BERLINE   \n",
       "1             1555             1555  715/2007*692/2008EURO5      BERLINE   \n",
       "2             1565             1565  715/2007*692/2008EURO5      BERLINE   \n",
       "3             1565             1565  715/2007*692/2008EURO5      BERLINE   \n",
       "4             1565             1565  715/2007*692/2008EURO5      BERLINE   \n",
       "\n",
       "       gamme carburant typ_boite nb_rapp etiquette  \n",
       "0  MOY-SUPER   Essence  Manuelle       6         E  \n",
       "1  MOY-SUPER   Essence  Manuelle       6         E  \n",
       "2  MOY-SUPER    Gazoil  Manuelle       6         C  \n",
       "3  MOY-SUPER    Gazoil  Manuelle       6         C  \n",
       "4  MOY-SUPER    Gazoil  Manuelle       6         C  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52308 entries, 0 to 52307\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   lib_mrq          52308 non-null  object \n",
      " 1   lib_mod_doss     52308 non-null  object \n",
      " 2   lib_mod          52308 non-null  object \n",
      " 3   dscom            52308 non-null  object \n",
      " 4   hybride          52308 non-null  object \n",
      " 5   puiss_admin_98   52308 non-null  int64  \n",
      " 6   puiss_max        52308 non-null  float64\n",
      " 7   conso_urb        52308 non-null  float64\n",
      " 8   conso_exurb      52308 non-null  float64\n",
      " 9   conso_mixte      52308 non-null  float64\n",
      " 10  co2              52308 non-null  float64\n",
      " 11  co_typ_1         52308 non-null  float64\n",
      " 12  nox              52308 non-null  float64\n",
      " 13  ptcl             52308 non-null  float64\n",
      " 14  masse_ordma_min  52308 non-null  int64  \n",
      " 15  masse_ordma_max  52308 non-null  int64  \n",
      " 16  champ_v9         52308 non-null  object \n",
      " 17  Carrosserie      52308 non-null  object \n",
      " 18  gamme            52308 non-null  object \n",
      " 19  carburant        52308 non-null  object \n",
      " 20  typ_boite        52308 non-null  object \n",
      " 21  nb_rapp          52308 non-null  int64  \n",
      " 22  etiquette        52308 non-null  object \n",
      "dtypes: float64(8), int64(4), object(11)\n",
      "memory usage: 9.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Donnees_propres.csv\")\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les colonnes qui contiennent des informations sur la marque ou le constructeur :\n",
    "lib_mrq, lib_mod_doss, lib_mod_ dscom ainsi que la variable champ_v9, co2 (nous avons les etiquettes), puiss_admin_98, co_typ_1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['lib_mrq', 'lib_mod_doss', 'lib_mod', 'dscom', 'champ_v9', 'co2', 'puiss_admin_98', 'co_typ_1',\n",
    "           'conso_urb', 'conso_exurb', 'conso_mixte']\n",
    "df_clear = df.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybride         2\n",
      "Carrosserie    11\n",
      "gamme           6\n",
      "carburant       4\n",
      "typ_boite       3\n",
      "etiquette       7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# On récupère les colonnes de type Object\n",
    "colonnes_object = df_clear.select_dtypes(include='object')\n",
    "\n",
    "# On calcule le nombre de modalités de chacune de ces variables\n",
    "categories_uniques = colonnes_object.nunique()\n",
    "print(categories_uniques)\n",
    "\n",
    "# 6 Variables catégorielles à réencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reencodage des variables categorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hybride'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'etiquette'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 1, 0, 5, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable hybride\n",
    "\n",
    "# On remplace les notes alphabétiques par les notes numériques correspondantes\n",
    "df_clear['hybride'] = df_clear['hybride'].replace({'oui':1, 'non': 0})\n",
    "display('hybride', df_clear['hybride'].unique())\n",
    "\n",
    "# Variable cible etiquette\n",
    "# On créé un dictionnaire qui contient les changements souhaités\n",
    "grade = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}\n",
    "\n",
    "# On remplace les notes alphabétiques par les notes numériques correspondantes\n",
    "df_clear['etiquette'] = df_clear['etiquette'].replace(grade)\n",
    "display('etiquette', df_clear['etiquette'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_clear, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52308 entries, 0 to 52307\n",
      "Data columns (total 32 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   hybride                          52308 non-null  int64  \n",
      " 1   puiss_max                        52308 non-null  float64\n",
      " 2   nox                              52308 non-null  float64\n",
      " 3   ptcl                             52308 non-null  float64\n",
      " 4   masse_ordma_min                  52308 non-null  int64  \n",
      " 5   masse_ordma_max                  52308 non-null  int64  \n",
      " 6   nb_rapp                          52308 non-null  int64  \n",
      " 7   etiquette                        52308 non-null  int64  \n",
      " 8   Carrosserie_BERLINE              52308 non-null  int64  \n",
      " 9   Carrosserie_BREAK                52308 non-null  int64  \n",
      " 10  Carrosserie_CABRIOLET            52308 non-null  int64  \n",
      " 11  Carrosserie_COMBISPACE           52308 non-null  int64  \n",
      " 12  Carrosserie_COMBISPCACE          52308 non-null  int64  \n",
      " 13  Carrosserie_COUPE                52308 non-null  int64  \n",
      " 14  Carrosserie_MINIBUS              52308 non-null  int64  \n",
      " 15  Carrosserie_MINISPACE            52308 non-null  int64  \n",
      " 16  Carrosserie_MONOSPACE            52308 non-null  int64  \n",
      " 17  Carrosserie_MONOSPACE COMPACT    52308 non-null  int64  \n",
      " 18  Carrosserie_TS TERRAINS/CHEMINS  52308 non-null  int64  \n",
      " 19  gamme_ECONOMIQUE                 52308 non-null  int64  \n",
      " 20  gamme_INFERIEURE                 52308 non-null  int64  \n",
      " 21  gamme_LUXE                       52308 non-null  int64  \n",
      " 22  gamme_MOY-INFER                  52308 non-null  int64  \n",
      " 23  gamme_MOY-SUPER                  52308 non-null  int64  \n",
      " 24  gamme_SUPERIEURE                 52308 non-null  int64  \n",
      " 25  carburant_Essence                52308 non-null  int64  \n",
      " 26  carburant_Essence/Elec           52308 non-null  int64  \n",
      " 27  carburant_Gasoil/Elec            52308 non-null  int64  \n",
      " 28  carburant_Gazoil                 52308 non-null  int64  \n",
      " 29  typ_boite_Auto                   52308 non-null  int64  \n",
      " 30  typ_boite_Manuelle               52308 non-null  int64  \n",
      " 31  typ_boite_Var_continue           52308 non-null  int64  \n",
      "dtypes: float64(3), int64(29)\n",
      "memory usage: 12.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['hybride', 'puiss_max', 'nox', 'ptcl', 'masse_ordma_min',\n",
       "       'masse_ordma_max', 'nb_rapp', 'etiquette', 'Carrosserie_BERLINE',\n",
       "       'Carrosserie_BREAK', 'Carrosserie_CABRIOLET', 'Carrosserie_COMBISPACE',\n",
       "       'Carrosserie_COMBISPCACE', 'Carrosserie_COUPE', 'Carrosserie_MINIBUS',\n",
       "       'Carrosserie_MINISPACE', 'Carrosserie_MONOSPACE',\n",
       "       'Carrosserie_MONOSPACE COMPACT', 'Carrosserie_TS TERRAINS/CHEMINS',\n",
       "       'gamme_ECONOMIQUE', 'gamme_INFERIEURE', 'gamme_LUXE', 'gamme_MOY-INFER',\n",
       "       'gamme_MOY-SUPER', 'gamme_SUPERIEURE', 'carburant_Essence',\n",
       "       'carburant_Essence/Elec', 'carburant_Gasoil/Elec', 'carburant_Gazoil',\n",
       "       'typ_boite_Auto', 'typ_boite_Manuelle', 'typ_boite_Var_continue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.info()\n",
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop(columns ='etiquette', axis = 1)\n",
    "y= df_encoded['etiquette']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premiers modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8939922573244754\n",
      "score données test 0.8729688396100173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83        31\n",
      "           1       0.83      0.88      0.86       249\n",
      "           2       0.87      0.80      0.83       427\n",
      "           3       0.79      0.77      0.78       324\n",
      "           4       0.80      0.87      0.83      3333\n",
      "           5       0.92      0.88      0.90      5968\n",
      "           6       1.00      0.93      0.96       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.87      0.85      0.86     10462\n",
      "weighted avg       0.88      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modele\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Certaines classes sont sous représentées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           80.645161  19.354839   0.000000   0.000000   0.000000   0.000000   \n",
      "1            1.606426  88.353414   9.638554   0.401606   0.000000   0.000000   \n",
      "2            0.000000   8.665105  80.093677  11.241218   0.000000   0.000000   \n",
      "3            0.000000   0.308642   8.333333  77.469136  13.888889   0.000000   \n",
      "4            0.000000   0.000000   0.000000   0.510051  86.828683  12.661266   \n",
      "5            0.000000   0.000000   0.000000   0.000000  11.528150  88.471850   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   6.923077   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.000000  \n",
      "6           93.076923  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Feature  Importance\n",
      "2                               nox    0.243543\n",
      "5                   masse_ordma_max    0.146017\n",
      "4                   masse_ordma_min    0.116566\n",
      "6                           nb_rapp    0.084116\n",
      "1                         puiss_max    0.078076\n",
      "29               typ_boite_Manuelle    0.070816\n",
      "28                   typ_boite_Auto    0.068786\n",
      "13              Carrosserie_MINIBUS    0.037828\n",
      "3                              ptcl    0.037507\n",
      "21                  gamme_MOY-INFER    0.020982\n",
      "22                  gamme_MOY-SUPER    0.019607\n",
      "7               Carrosserie_BERLINE    0.017423\n",
      "27                 carburant_Gazoil    0.010351\n",
      "24                carburant_Essence    0.009667\n",
      "20                       gamme_LUXE    0.009000\n",
      "23                 gamme_SUPERIEURE    0.006512\n",
      "17  Carrosserie_TS TERRAINS/CHEMINS    0.005283\n",
      "8                 Carrosserie_BREAK    0.003996\n",
      "19                 gamme_INFERIEURE    0.002635\n",
      "9             Carrosserie_CABRIOLET    0.001846\n",
      "12                Carrosserie_COUPE    0.001815\n",
      "0                           hybride    0.001648\n",
      "16    Carrosserie_MONOSPACE COMPACT    0.001284\n",
      "10           Carrosserie_COMBISPACE    0.001035\n",
      "25           carburant_Essence/Elec    0.001032\n",
      "26            carburant_Gasoil/Elec    0.000920\n",
      "30           typ_boite_Var_continue    0.000656\n",
      "15            Carrosserie_MONOSPACE    0.000557\n",
      "14            Carrosserie_MINISPACE    0.000334\n",
      "18                 gamme_ECONOMIQUE    0.000116\n",
      "11          Carrosserie_COMBISPCACE    0.000046\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "features = X.columns  \n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On testera plus le meme modele avec les 5 variables qui ont le plus d'importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest avec l'argument class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8847440615590498\n",
      "score données test 0.8698145670043969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        31\n",
      "           1       0.82      0.87      0.84       249\n",
      "           2       0.87      0.79      0.83       427\n",
      "           3       0.70      0.87      0.78       324\n",
      "           4       0.78      0.91      0.84      3333\n",
      "           5       0.96      0.85      0.90      5968\n",
      "           6       0.75      0.99      0.85       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.80      0.87      0.83     10462\n",
      "weighted avg       0.88      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modele avec l'argument class_weight='balanced'\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           77.419355  22.580645   0.000000   0.000000   0.000000   0.000000   \n",
      "1            3.212851  87.148594   9.236948   0.401606   0.000000   0.000000   \n",
      "2            0.000000   9.133489  78.688525  12.177986   0.000000   0.000000   \n",
      "3            0.000000   0.617284   8.024691  87.037037   4.320988   0.000000   \n",
      "4            0.000000   0.000000   0.000000   1.950195  90.999100   7.050705   \n",
      "5            0.000000   0.000000   0.000000   0.000000  14.175603  85.103887   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   0.769231   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.720509  \n",
      "6           99.230769  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest avec plus de branches : 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8846723701190078\n",
      "score données test 0.8700057350411011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76        31\n",
      "           1       0.82      0.87      0.85       249\n",
      "           2       0.88      0.79      0.83       427\n",
      "           3       0.71      0.88      0.78       324\n",
      "           4       0.78      0.91      0.84      3333\n",
      "           5       0.96      0.85      0.90      5968\n",
      "           6       0.75      0.99      0.85       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.81      0.87      0.83     10462\n",
      "weighted avg       0.88      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           77.419355  22.580645   0.000000   0.000000   0.000000   0.000000   \n",
      "1            3.212851  87.148594   9.236948   0.401606   0.000000   0.000000   \n",
      "2            0.000000   8.899297  78.688525  12.412178   0.000000   0.000000   \n",
      "3            0.000000   0.617284   7.716049  87.962963   3.703704   0.000000   \n",
      "4            0.000000   0.000000   0.000000   1.950195  90.969097   7.080708   \n",
      "5            0.000000   0.000000   0.000000   0.000000  14.175603  85.103887   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   0.769231   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.720509  \n",
      "6           99.230769  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reechantillonage SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8880179706543039\n",
      "score données test 0.8702924870961575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        31\n",
      "           1       0.82      0.86      0.84       249\n",
      "           2       0.88      0.77      0.82       427\n",
      "           3       0.71      0.87      0.78       324\n",
      "           4       0.78      0.91      0.84      3333\n",
      "           5       0.95      0.85      0.90      5968\n",
      "           6       0.78      0.96      0.86       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.80      0.86      0.83     10462\n",
      "weighted avg       0.88      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           77.419355  22.580645   0.000000   0.000000   0.000000   0.000000   \n",
      "1            4.016064  86.345382   9.638554   0.000000   0.000000   0.000000   \n",
      "2            0.000000   9.367681  77.049180  13.583138   0.000000   0.000000   \n",
      "3            0.000000   0.308642   6.790123  86.728395   6.172840   0.000000   \n",
      "4            0.000000   0.000000   0.000000   1.710171  91.089109   7.200720   \n",
      "5            0.000000   0.000000   0.000000   0.016756  14.008043  85.371984   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   3.846154   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.603217  \n",
      "6           96.153846  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reechantillonage undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.9655419956927495\n",
      "score données test 0.8129420760848786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64        31\n",
      "           1       0.69      0.74      0.72       249\n",
      "           2       0.81      0.65      0.72       427\n",
      "           3       0.52      0.87      0.65       324\n",
      "           4       0.76      0.79      0.78      3333\n",
      "           5       0.91      0.83      0.87      5968\n",
      "           6       0.42      0.99      0.59       130\n",
      "\n",
      "    accuracy                           0.81     10462\n",
      "   macro avg       0.65      0.84      0.71     10462\n",
      "weighted avg       0.83      0.81      0.82     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_resampled, y_train_resampled))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Moins précis que le modele avec les données non rééchantillonées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction           0          1          2          3          4          5  \\\n",
      "Réel                                                                            \n",
      "0           100.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "1            13.654618  73.895582  11.244980   1.204819   0.000000   0.000000   \n",
      "2             0.234192  17.096019  65.105386  17.564403   0.000000   0.000000   \n",
      "3             0.000000   2.469136  10.185185  87.037037   0.308642   0.000000   \n",
      "4             0.000000   0.000000   0.150015   5.010501  79.417942  15.061506   \n",
      "5             0.000000   0.000000   0.000000   0.184316  13.991287  83.009383   \n",
      "6             0.000000   0.000000   0.000000   0.000000   0.000000   0.769231   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.360036  \n",
      "5            2.815013  \n",
      "6           99.230769  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.882903981264637\n",
      "score données test 0.8689543108392277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73        31\n",
      "           1       0.81      0.87      0.84       249\n",
      "           2       0.87      0.76      0.81       427\n",
      "           3       0.71      0.89      0.79       324\n",
      "           4       0.78      0.91      0.84      3333\n",
      "           5       0.95      0.85      0.90      5968\n",
      "           6       0.68      1.00      0.81       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.78      0.86      0.82     10462\n",
      "weighted avg       0.88      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(eval_metric=\"merror\", use_label_encoder=False)\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           77.419355  19.354839   3.225806   0.000000   0.000000   0.000000   \n",
      "1            4.417671  86.746988   8.433735   0.401606   0.000000   0.000000   \n",
      "2            0.000000  10.538642  76.112412  13.114754   0.234192   0.000000   \n",
      "3            0.000000   0.308642   7.716049  88.580247   3.395062   0.000000   \n",
      "4            0.000000   0.000000   0.000000   1.800180  90.879088   7.320732   \n",
      "5            0.000000   0.000000   0.000000   0.016756  13.823727  85.120643   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "\n",
      "Prédiction           6  \n",
      "Réel                    \n",
      "0             0.000000  \n",
      "1             0.000000  \n",
      "2             0.000000  \n",
      "3             0.000000  \n",
      "4             0.000000  \n",
      "5             1.038874  \n",
      "6           100.000000  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecion de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste le premier modèle avec les variables qui ont le plus d'importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Donnees_propres.csv\")\n",
    "\n",
    "X = df[['nox', 'masse_ordma_min', 'masse_ordma_max', 'nb_rapp', 'puiss_max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etiquette'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 1, 0, 5, 6])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variable cible etiquette\n",
    "# On créé un dictionnaire qui contient les changements souhaités\n",
    "grade = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}\n",
    "\n",
    "# On remplace les notes alphabétiques par les notes numériques correspondantes\n",
    "y= df['etiquette']\n",
    "y = y.replace(grade)\n",
    "display('etiquette', y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8925106342302729\n",
      "score données test 0.8678073026190021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70        31\n",
      "           1       0.79      0.87      0.83       249\n",
      "           2       0.82      0.78      0.80       427\n",
      "           3       0.76      0.71      0.73       324\n",
      "           4       0.79      0.87      0.83      3333\n",
      "           5       0.93      0.88      0.90      5968\n",
      "           6       0.99      0.93      0.96       130\n",
      "\n",
      "    accuracy                           0.87     10462\n",
      "   macro avg       0.83      0.81      0.82     10462\n",
      "weighted avg       0.87      0.87      0.87     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modele\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           64.516129  32.258065   3.225806   0.000000   0.000000   0.000000   \n",
      "1            2.008032  86.746988   9.236948   2.008032   0.000000   0.000000   \n",
      "2            0.234192   9.601874  77.517564  11.475410   1.170960   0.000000   \n",
      "3            0.000000   2.160494  12.654321  71.296296  13.888889   0.000000   \n",
      "4            0.000000   0.000000   0.270027   0.600060  87.458746  11.671167   \n",
      "5            0.000000   0.000000   0.000000   0.000000  12.097855  87.885389   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   6.923077   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.016756  \n",
      "6           93.076923  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection des données purement caracteristiques de la voiture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Donnees_propres.csv\")\n",
    "df_caract = df[['carburant','hybride','masse_ordma_min','masse_ordma_max',\n",
    "                \"puiss_max\",'Carrosserie','typ_boite','nb_rapp', 'gamme']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace les notes alphabétiques par les notes numériques correspondantes\n",
    "df_caract['hybride'] = df_caract['hybride'].replace({'oui':1, 'non': 0})\n",
    "\n",
    "df_encoded = pd.get_dummies(df_caract, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded, y, test_size=0.2, random_state=12)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8337475505424652\n",
      "score données test 0.8124641559931179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        31\n",
      "           1       0.77      0.85      0.81       249\n",
      "           2       0.84      0.76      0.80       427\n",
      "           3       0.76      0.74      0.75       324\n",
      "           4       0.77      0.67      0.72      3333\n",
      "           5       0.83      0.90      0.86      5968\n",
      "           6       1.00      0.92      0.96       130\n",
      "\n",
      "    accuracy                           0.81     10462\n",
      "   macro avg       0.80      0.77      0.79     10462\n",
      "weighted avg       0.81      0.81      0.81     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modele\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           58.064516  41.935484   0.000000   0.000000   0.000000   0.000000   \n",
      "1            3.614458  84.738956  10.843373   0.803213   0.000000   0.000000   \n",
      "2            0.234192  11.241218  76.346604  11.709602   0.468384   0.000000   \n",
      "3            0.000000   0.617284  10.185185  74.382716  14.814815   0.000000   \n",
      "4            0.000000   0.000000   0.030003   0.690069  66.816682  32.463246   \n",
      "5            0.000000   0.000000   0.000000   0.000000  10.237936  89.762064   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   7.692308   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.000000  \n",
      "6           92.307692  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Feature  Importance\n",
      "2                   masse_ordma_max    0.218037\n",
      "1                   masse_ordma_min    0.158021\n",
      "3                         puiss_max    0.129075\n",
      "20                   typ_boite_Auto    0.105197\n",
      "4                           nb_rapp    0.086837\n",
      "21               typ_boite_Manuelle    0.078048\n",
      "15              Carrosserie_MINIBUS    0.054772\n",
      "26                  gamme_MOY-INFER    0.029993\n",
      "9               Carrosserie_BERLINE    0.029150\n",
      "27                  gamme_MOY-SUPER    0.026776\n",
      "8                  carburant_Gazoil    0.016530\n",
      "5                 carburant_Essence    0.015408\n",
      "25                       gamme_LUXE    0.012297\n",
      "28                 gamme_SUPERIEURE    0.007577\n",
      "19  Carrosserie_TS TERRAINS/CHEMINS    0.007513\n",
      "10                Carrosserie_BREAK    0.005795\n",
      "24                 gamme_INFERIEURE    0.003297\n",
      "11            Carrosserie_CABRIOLET    0.002681\n",
      "14                Carrosserie_COUPE    0.002508\n",
      "0                           hybride    0.002257\n",
      "18    Carrosserie_MONOSPACE COMPACT    0.002126\n",
      "6            carburant_Essence/Elec    0.001394\n",
      "7             carburant_Gasoil/Elec    0.001322\n",
      "12           Carrosserie_COMBISPACE    0.001147\n",
      "22           typ_boite_Var_continue    0.000822\n",
      "17            Carrosserie_MONOSPACE    0.000741\n",
      "16            Carrosserie_MINISPACE    0.000471\n",
      "23                 gamme_ECONOMIQUE    0.000143\n",
      "13          Carrosserie_COMBISPCACE    0.000065\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "\n",
    "features = X_train.columns  \n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les 5 caractéristiques les plus importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caract = df[['masse_ordma_min','masse_ordma_max',\"puiss_max\",'typ_boite','nb_rapp']]\n",
    "\n",
    "df_encoded = pd.get_dummies(df_caract, dtype='int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded, y, test_size=0.2, random_state=12)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score données train 0.8286335611527984\n",
      "score données test 0.8072070349837507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        31\n",
      "           1       0.75      0.79      0.77       249\n",
      "           2       0.81      0.74      0.77       427\n",
      "           3       0.70      0.73      0.71       324\n",
      "           4       0.79      0.64      0.70      3333\n",
      "           5       0.82      0.91      0.86      5968\n",
      "           6       0.99      0.92      0.96       130\n",
      "\n",
      "    accuracy                           0.81     10462\n",
      "   macro avg       0.78      0.76      0.77     10462\n",
      "weighted avg       0.81      0.81      0.80     10462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modele\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Résultats\n",
    "print('score données train', model.score(X_train_scaled, y_train))\n",
    "print('score données test', model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction          0          1          2          3          4          5  \\\n",
      "Réel                                                                           \n",
      "0           61.290323  35.483871   3.225806   0.000000   0.000000   0.000000   \n",
      "1            3.614458  78.714859  12.048193   5.622490   0.000000   0.000000   \n",
      "2            0.702576   9.836066  74.473068  13.114754   1.873536   0.000000   \n",
      "3            0.000000   3.086420  12.345679  72.530864  12.037037   0.000000   \n",
      "4            0.000000   0.090009   0.180018   0.870087  63.696370  35.163516   \n",
      "5            0.000000   0.000000   0.000000   0.000000   8.930965  91.052279   \n",
      "6            0.000000   0.000000   0.000000   0.000000   0.000000   7.692308   \n",
      "\n",
      "Prédiction          6  \n",
      "Réel                   \n",
      "0            0.000000  \n",
      "1            0.000000  \n",
      "2            0.000000  \n",
      "3            0.000000  \n",
      "4            0.000000  \n",
      "5            0.016756  \n",
      "6           92.307692  \n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "conf_matrix = pd.crosstab(y_test, y_pred, rownames=['Réel'], colnames=['Prédiction'], dropna=False)\n",
    "\n",
    "# Calculer les pourcentages par ligne\n",
    "conf_matrix_percentage = conf_matrix.div(conf_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
