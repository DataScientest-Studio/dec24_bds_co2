import streamlit as st
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

from imblearn.over_sampling import SMOTE

import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler

st.title("DS Octobre - Projet CO2")
st.sidebar.title('Sommaire')
pages=['Introduction', 'Exploration', 'Mod√©lisation']
page = st.sidebar.radio('Aller vers', pages)


# premier onglet - introduction au projet
if page == pages[0] : 
    st.write('# Introduction')
    st.write("Le changement climatique est l‚Äôun des d√©fis majeurs du XXIe si√®cle, et la r√©duction des √©missions de CO‚ÇÇ est un enjeu central dans la lutte contre le r√©chauffement global. Parmi les secteurs les plus polluants, le transport joue un r√¥le cl√© : en 2019, il √©tait responsable d‚Äôenviron un quart des √©missions totales de CO‚ÇÇ de l‚ÄôUnion europ√©enne, dont 71,7 % provenaient du transport routier. Les voitures personnelles, en particulier, repr√©sentaient 60,6% des √©missions de CO‚ÇÇ li√©es √† ce secteur."
             "Malgr√© les efforts pour limiter ces √©missions, on observe une augmentation de 33,5 % entre 1990 et 2019. Selon les projections actuelles, la diminution des √©missions du transport d‚Äôici 2050 ne serait que de 22 %, bien en de√ß√† des objectifs n√©cessaires pour respecter les engagements climatiques."
             "Face √† cette probl√©matique, deux principales strat√©gies permettent de r√©duire l‚Äôempreinte carbone des v√©hicules : am√©liorer leur efficacit√© √©nerg√©tique et modifier leur source d‚Äô√©nergie, en passant par exemple √† des carburants alternatifs ou √† l‚Äô√©lectrification."
             "Dans ce contexte, notre projet vise √† pr√©dire les √©missions de CO‚ÇÇ des v√©hicules en fonction de leurs caract√©ristiques. En d√©veloppant un mod√®le de pr√©diction pr√©cis, nous pourrions contribuer √† mieux comprendre les facteurs influen√ßant ces √©missions et ainsi aider les constructeurs √† voir comment optimiser leurs prochaines s√©ries de voiture lorsque ceux-ci sont soucieux de leur impact environnemental."
             "")
    st.image("images\image1.png")
    st.write('## Identification de la probl√©matique')
    url1 = 'https://www.data.gouv.fr/fr/datasets/emissions-de-co2-et-de-polluants-des-vehicules-commercialises-en-france/#_'
    url2 = 'https://co2cars.apps.eea.europa.eu/?source=%7B%22track_total_hits%22%3Atrue%2C%22query%22%3A%7B%22bool%22%3A%7B%22must%22%3A%5B%7B%22constant_score%22%3A%7B%22filter%22%3A%7B%22bool%22%3A%7B%22must%22%3A%5B%7B%22bool%22%3A%7B%22should%22%3A%5B%7B%22term%22%3A%7B%22year%22%3A2014%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2013%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2012%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2011%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2010%7D%7D%5D%7D%7D%2C%7B%22bool%22%3A%7B%22should%22%3A%5B%7B%22term%22%3A%7B%22scStatus%22%3A%22Final%22%7D%7D%5D%7D%7D%5D%7D%7D%7D%7D%5D%7D%7D%2C%22display_type%22%3A%22tabular%22%7D'

    st.write("Nous sommes partis des donn√©es disponibles sur le site [data.gouv.fr](%s)" % url1 , " qui contiennent les √©missions des CO2 et les caract√©ristiques des v√©hicules commercialis√©s en France en 2014. "
             "Nous avons √©galement trouv√© des donn√©es int√©ressantes de [l'Agence europ√©enne pour l'environnement](%s)" % url2 , " qui viennent compl√©ter certaines informations manquantes au premier jeu de donn√©es."
             "Nous avons √† faire √† une probl√©matique de classification supervis√©e. A partir de leurs caract√©ristiques, nous cherchons √† classer les v√©hicules selon les 7 cat√©gories d‚Äô√©mission de C02 en nous basant sur l‚Äô√©tiquette √©nerg√©tique des v√©hicules. "
             "")
    st.image("images\image2.png")
    st.write("Notre variable cible est d√©j√† pr√©sente dans le jeu de donn√©es, c‚Äôest la variable co2. Nous transformerons cette variable, actuellement quantitative, en une variable cat√©gorielle pour plus de visibilit√© lors de la transmission des r√©sultats.")

# deuxi√®me onglet - exploration de nos datasets
if page == pages[1] :
    st.write('# Exploration')

    # S√©lection du dataset dans la barre lat√©rale
    dataset_select = ['Dataset 1', 'Dataset Merge']
    dataset_selector = st.sidebar.radio('Choix du dataset', dataset_select)

    if dataset_selector == dataset_select[0] :
        df=pd.read_csv("mars-2014-complete.csv",encoding='ISO-8859-1', sep = ';')
        st.write('## Dataset 1')
        df=pd.read_csv("mars-2014-complete.csv",encoding='ISO-8859-1', sep = ';')

        st.write('### Pr√©sentation des donn√©es avant nettoyage')
        # Affichage des 3 premi√®res lignes du DataFrame
        st.write('#### Pr√©sentation du dataframe')
        st.dataframe(df.head(5))

        # Affichage des dimensions du DataFrame
        st.write('#### Dimensions du dataframe')
        st.dataframe(pd.DataFrame({"Dimension": ["Lignes", "Colonnes"], "Valeur": df.shape}))

        st.write('#### Informations g√©n√©rales')
        # Affichage des informations g√©n√©rales du DataFrame
        st.dataframe(pd.DataFrame({
        "Colonnes": df.columns,
        "Type": df.dtypes,
        "Pourcentage Manquantes": (df.isnull().sum() / len(df)) * 100,
        "Nb. Valeurs Uniques": df.nunique()
        }))


        st.write('### Gestion des valeurs manquantes')
        st.write('Nous supprimons toutes les valeurs manquantes')
        if st.button("üîç Cliquer pour plus de d√©tails", key = "1"):
            st.write("Pour les variables conserv√©es, √©tant donn√© que le nombre de valeurs manquantes repr√©sente un pourcentage faible de l'enti√®ret√© des valeurs du dataset, on a d√©cid√© de supprimer la ligne s'il manquait au moins une valeur. On ne perd pas √©norm√©ment d‚Äô√©chantillons en appliquant cette strat√©gie. On pr√©f√®re supprimer l‚Äôindividu plut√¥t que de remplacer une valeur manquante par le mode le plus pr√©sent ou la m√©diane car cette nouvelle valeur reste hypoth√©tique.")     


        st.write('### S√©lection des variables')
        st.write("Dans un premier temps nous avons d√©cid√© de supprimer les variables suivantes :   "
        "**cnit** (Code National d‚ÄôIdentification du Type, **tvv** (Type Variante Version), **hc** (r√©sultats d'essai), **hcnox** (r√©sultats d'essai), **date_maj** (date de mise √† jour)")
        
        if st.button("üîç Cliquer pour plus de d√©tails", key = "2"):
            st.write(""" Nous nous int√©ressons d‚Äôabord au pourcentage de valeurs manquantes. Les variables hc et date_maj en contiennent plus de 80%. Nous d√©cidons donc de supprimer ces variables. 

            La variable hcnox √©tant directement reli√©e √† la variable hc, nous d√©cidons de la supprimer √©galement.

            La variable ptcl contient 5% de donn√©es manquantes. Apr√®s avoir regard√© la proportion de ces donn√©es manquantes en fonction de la marque de voiture, nous avons pu voir que la majorit√© des donn√©es manquantes proviennent de la marque Mercedes qui est une classe largement majoritaire dans notre jeu de donn√©es. Garder cette variable en ne supprimant que les lignes contenant des valeurs manquantes nous para√Æt donc pertinent puisque nous ne perdons pas beaucoup d'informations.

            Les variables cnit (Code National d‚ÄôIdentification du Type) et tvv (Type Variante Version) sont des variables qui correspondent √† des ID d‚Äôidentification. Ainsi ces variables ne sont pas n√©cessaires comme variables explicatives pour le mod√®le, mais elles peuvent √™tre utiles comme clef pour lier et fusionner ce dataset avec d‚Äôautres dataset (Voir plus tard).

            La variable co2 est utile pour cr√©er notre variable cible. Elle renseigne la quantit√© d‚Äô√©mission de CO2 en g/km. Lorsque l‚Äôon regarde les √©tiquettes de pollution, les diff√©rentes cat√©gories se basent sur cette donn√©e. Ainsi on cr√©e une nouvelle variable que l‚Äôon nomme Category dont la valeur est d√©termin√©e √† partir de l‚Äôimage ci-dessous. Cette variable sera notre variable cible pour notre probl√®me de classification.

            Les variables puiss_max, conso_urb, conso_exurb, conso_mixte, co_typ_1, nox et ptcl sont initialement des cha√Ænes de caract√®res. Cependant, ce sont des variables quantitatives dans les faits. Ainsi, il est n√©cessaire de changer leur type pour avoir des flottants.
            Toutes les autres variables pas encore mentionn√©es sont conserv√©es. Cela repr√©sente des variables cat√©gorielles ou des variables quantitatives qui nous semblent pertinentes comme variables explicatives pour le mod√®le. Nous verrons un peu plus en d√©tail chacune de ces variables, leurs modes pour les variables cat√©gorielles et leur r√©partition pour les variables quantitatives. 
            """)

        # nettoyage du dataset1
        #
        df = df.iloc[:, :-4]
        to_drop = ["cnit", "tvv", "hc", "hcnox", "date_maj"]
        df_clear = df.drop(to_drop, axis = 1)
        df_without_Na = df_clear.dropna()
        quantitative_col = ["co2","puiss_admin_98","puiss_max","conso_urb","conso_exurb","conso_mixte","co_typ_1","nox","ptcl","masse_ordma_min","masse_ordma_max"]
        df_quantitative = df_without_Na[quantitative_col]

        for name in df_quantitative:
            # Remplacement des virgules par des points et changement de type
            df_without_Na[name] = pd.to_numeric(df_without_Na[name].astype(str).str.replace(',', '.'), errors = 'coerce')
            df_quantitative[name] = pd.to_numeric(df_without_Na[name].astype(str).str.replace(',', '.'), errors = 'coerce')
        
        df_without_Na['typ_boite'] = None 
        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('M'), 'typ_boite'] = 'Manuelle'

        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('A'), 'typ_boite'] = 'Auto'

        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('V'), 'typ_boite'] = 'Var_continue'

        # On supprime les Nan cr√©√©es
        df_without_Na = df_without_Na.dropna(subset=['typ_boite'])
 
        df_without_Na['nb_rapp'] = None 

        list_vitesse = ['0','5', '6', '7', '8', '9']

        for i in list_vitesse:
            df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.contains(i), 'nb_rapp'] = i

        # On supprimer les Nan cr√©√©es
        df_without_Na = df_without_Na.dropna(subset=['nb_rapp'])

        rapport_counts = df_without_Na['nb_rapp'].value_counts()

        #ajout des √©tiquettes
        bins = [0, 100, 120, 140, 160, 200, 250, float('inf')]
        labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G']

        df_without_Na['category'] = pd.cut(df_without_Na['co2'], bins=bins, labels=labels, right=True)

        #fin du nettoyage
        

        st.write('## Datavizualisation')
        st.write("Voici quelques graphes qui permettent de mieux comprendre notre jeu de donn√©es et de voir les modification √† apporter.")

        st.write("### ‚õΩ Type de carburant")
        fig, ax = plt.subplots()
        sns.boxplot(data=df_without_Na, x='cod_cbr', y='co2', palette="viridis", ax=ax)
        plt.xticks(rotation=45, fontsize=10, ha='right')
        plt.xlabel('Type de carburant', fontsize=12)
        plt.ylabel('√âmission de CO2', fontsize=12)
        plt.title('Distribution du CO2 par type de carburant', fontsize=14)
        st.pyplot(fig)

        st.write("Nous supprimons les carburants **FE**, **GN**, et **GL**")


        st.write("### üïπÔ∏è Nombre de rapports et type de boite de vitesses")
        # plot c√¥te √† c√¥te
        fig, axes = plt.subplots(ncols=2, figsize=(12, 5))
        # Barplot du type de boite
        sns.countplot(data=df_without_Na, x='typ_boite', palette="viridis", ax=axes[0])
        axes[0].set_xlabel('Type de boite de vitesse', fontsize=12)
        axes[0].set_ylabel('Count', fontsize=12)
        axes[0].set_title('R√©partition des boites de vitesses', fontsize=14)

        # Barplot du nombre de rapports
        sns.countplot(data=df_without_Na, x='nb_rapp', palette="viridis", ax=axes[1])
        axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, fontsize=10, ha='right')
        axes[1].set_xlabel('Nombre de rapports', fontsize=12)
        axes[1].set_ylabel('Count', fontsize=12)
        axes[1].set_title('R√©partition des nombres de rapports', fontsize=14)
        st.pyplot(fig)
        
        # plot c√¥te √† c√¥te
        fig, axes = plt.subplots(ncols=2, figsize=(12, 5))
        sns.boxplot(data=df_without_Na, x='typ_boite', y='co2', palette="viridis", ax=axes[0])
        axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, fontsize=10, ha='right')  
        axes[0].set_xlabel('Boites de vitesse', fontsize=12)
        axes[0].set_ylabel('CO2', fontsize=12)
        axes[0].set_title('CO2 en fonction du type de boite de vitesse', fontsize=14) 

        # Boxplot : Nombre de vitesses vs CO2
        sns.boxplot(data=df_without_Na, x='nb_rapp', y='co2', palette="viridis", ax=axes[1])
        axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, fontsize=10, ha='right')  
        axes[1].set_xlabel('Nombre de vitesses', fontsize=12)
        axes[1].set_ylabel('CO2', fontsize=12)
        axes[1].set_title('CO2 en fonction du nombre de vitesses', fontsize=14) 
        st.pyplot(fig)

        # Repartition des cat√©gories d'√©mission de CO2
        st.write("### üåç R√©partition des cat√©gories d'√©mission de CO2 / Variable cible")
        fig = plt.figure()
        sns.countplot(data=df_without_Na, x ='category', palette="viridis")
        plt.xticks(rotation=45, fontsize=10, ha='right')  
        plt.xlabel('Etiquette', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title("R√©partition des cat√©gories d'emission de CO2", fontsize=14) 
        plt.tight_layout()
        st.pyplot(fig)


        if st.button("üîç Voir d'autres graphiques", key = "3"):

            # Puissance max
            st.write("### ‚ö° Puissance maximale")
            fig, ax = plt.subplots()
            sns.scatterplot(x="puiss_max", y="co2", data=df_without_Na, hue="gamme", ax=ax)
            plt.xlabel("Puissance max")
            plt.ylabel("CO2")
            plt.title("Co2 en fonction de la puissance max et de la gamme du v√©hicule")
            st.pyplot(fig)

            # R√©partition des carrosseries
            st.write("### üöó R√©partition des carrosseries")
            fig = plt.figure()
            sns.countplot(data=df_without_Na, x ='Carrosserie', palette="viridis")
            plt.xticks(rotation=45, fontsize=10, ha='right')  
            plt.xlabel('Carosserie', fontsize=12)
            plt.ylabel('Count', fontsize=12)
            plt.title('R√©partition des carosserie', fontsize=14) 
            st.pyplot(fig)

            # R√©partition des gammes
            st.write("### üèéÔ∏è R√©partition des gammes")
            fig = plt.figure()
            sns.countplot(data=df_without_Na, x ='gamme', palette="viridis")
            plt.xticks(rotation=45, fontsize=10, ha='right')  
            plt.xlabel('Gamme', fontsize=12)
            plt.ylabel('Count', fontsize=12)
            plt.title('R√©partition des gammes', fontsize=14) 
            st.pyplot(fig)
    
    
    # Exmploration des donn√©es merged
    if dataset_selector == dataset_select[1] :
        df=pd.read_csv("data_merge_v2.csv")
        st.write('## Dataset Merge')

        st.write('### Fusion des deux datasets')
        st.write('Voici un graphe qui permet de comprendre comment la fusion a √©t√© faite')
        st.image("images\Schema merge.png")

        st.write('### Apper√ßu des datasets fusionn√©s')
        st.dataframe(df.head(5))


        st.write('### Datavizualisation')
        fig = plt.figure()
        sns.boxplot(y=df["ec (cm3)"])
        plt.title('R√©partion des valeurs cylindr√©s des moteurs (Ec (cm3))')
        st.pyplot(fig)
        
        fig = plt.figure()
        sns.boxplot(y=df["W (mm)"])
        plt.title('R√©partition des valeurs du diam√®tres des roues (W (mm))')
        st.pyplot(fig)

        fig = plt.figure()
        sns.scatterplot(data=df, x='ec (cm3)', y='puiss_max', hue='category')
        plt.xlabel("Engine Capacity")
        plt.ylabel("Puissance maximale")
        plt.title("La puissance maximale en fonction de capacit√© du moteur pour chaque cat√©gorie d'√©mission de CO2")
        st.pyplot(fig)


if page == pages[2] :
    st.write('# Mod√©lisation')

    # S√©lection du dataset dans la barre lat√©rale
    dataset_select = ['Dataset 1', 'Dataset Merge']
    dataset_selector = st.sidebar.radio('Choix du dataset', dataset_select)

    # Charger le dataset choisi
    if dataset_selector == dataset_select[0]:
        df = pd.read_csv("Donnees_propres.csv")

        # Pretraitement des donn√©es
        # Selection des variables
        to_drop = ['lib_mrq', 'lib_mod_doss', 'lib_mod', 'dscom', 'champ_v9', 'co2', 'puiss_admin_98', 'co_typ_1',
           'conso_urb', 'conso_exurb', 'conso_mixte']
        df_clear = df.drop(to_drop, axis = 1)
        # Reencodage de Hybride
        df_clear['hybride'] = df_clear['hybride'].replace({'oui':1, 'non': 0})

        # Reencodage categoy
        Etiquette = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}
        df_clear['category'] = df_clear['category'].replace(Etiquette)

        # R√©encodage des autres variables cat√©gorielles √† l'aide d'un get_dummies
        df_encoded = pd.get_dummies(df_clear, dtype='int')
        st.markdown("""
        Apr√®s avoir nettoy√© les donn√©es, nous avons r√©encod√© les variables cat√©gorielles   
        """)
        st.write("### Affichage des donn√©es r√©√©ncod√©es")
        st.dataframe(df_encoded.head(5))

        # S√©paration des donn√©es en variables explicatives et cible
        X = df_encoded.drop(columns ='category', axis = 1)
        y= df_encoded['category']

        # Split des donn√©es en train et test
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)

        # Standardisation des donn√©es
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test) 

        # Premiers mod√®les
        st.write('## 1. Premiers mod√®les')

        st.write('### Premiers mod√®les avec diff√©rents param√®tres')

        # Bibliotheques
        import joblib
        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
        import plotly.express as px


        models_dict = {
            "Random Forest (300 arbres)": "Mod√®les_data1\RF_300",
            "Random Forest (500 arbres)": "Mod√®les_data1\RF_500",
            "Random Forest (Balanced)": "Mod√®les_data1\RF_weight",
            "Random Forest (GridsearchCV)": "Mod√®les_data1\RF_gridsearch",
            "XGBoost": "Mod√®les_data1\XGB"
        }

        selected_model_name = st.selectbox("Choisissez un mod√®le :", list(models_dict.keys()))

        # Charger le mod√®le s√©lectionn√©
        model_path = models_dict[selected_model_name]
        model = joblib.load(model_path)

        # Faire les pr√©dictions
        y_pred = model.predict(X_test_scaled)

        # Calculer les m√©triques
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)
        conf_matrix = confusion_matrix(y_test, y_pred, normalize='true')

    # Affichage des r√©sultats
        st.write(f"#### R√©sultats pour : {selected_model_name}")
        st.write(f"**Accuracy :** {accuracy:.4f}")
        st.progress(int(accuracy * 100))  # Barre de progression pour l'accuracy

        # Pr√©parer les donn√©es pour le tableau (exclure les "avg" pour ne garder que les classes r√©elles)
        data = []
        for classe, valeurs in report.items():
            if isinstance(valeurs, dict):
                if 'avg' not in classe.lower():  # Exclure les moyennes 'avg'
                    f1_score = valeurs.get("f1-score", None)
                    support = valeurs.get("support", None)
                    precision = valeurs.get("precision", None)
                    recall = valeurs.get("recall", None)
                    if f1_score is not None:
                        data.append([classe,precision, recall, f1_score, support])

        # Cr√©er un DataFrame pour afficher les r√©sultats dans un tableau
        df_results = pd.DataFrame(data, columns=["Classe" , "Precision", "Recall", "F1-Score", "Support"])
        df_results = df_results.reset_index(drop=True)

         # Affichage de la matrice de confusion avec une meilleure esth√©tique
        if st.button(" üîç Afficher la matrice de confusion", key = "param"):
            st.write("#### Matrice de confusion normalis√©e :")
            conf_matrix_df = pd.DataFrame(conf_matrix, index=[f"Classe {i}" for i in range(len(conf_matrix))],
                              columns=[f"Classe {i}" for i in range(len(conf_matrix))])

            # Arrondir les valeurs de la matrice de confusion
            conf_matrix_df = conf_matrix_df.round(2)  # Arrondir √† 2 d√©cimales

            fig = px.imshow(conf_matrix_df, text_auto=True, aspect="auto", title="Matrice de confusion",
                    labels={'x': 'Pr√©dictions', 'y': 'Vraies valeurs'})
            fig.update_xaxes(side="top")
            st.plotly_chart(fig, key="conf_matrix_1")


        st.write('### Premiers mod√®les avec diff√©rents donn√©es')
        st.markdown("""
        Les donn√©es les plus importantes qui sortent du premier RandomForest le plus performant sont (nous ne prendrons que les 5 plus importantes) :   
        """)
        st.image("Images\importances_features.png")

        ("""
        Les donn√©es caract√©ristiques uniquement sont :
        - carburant
        - hybride
        - masse_ordma_min
        - masse_ordma_max
        - puiss_max
        - Carrosserie   
        - typ_boite
        - nb_rapp
        - gamme


        Choisissez un mod√®le et voyez ses performances en termes d'accuracy, scores F1 et matrice de confusion.
        """)

        # R√©cup√©ration des donn√©es
        df=pd.read_csv("Donnees_propres.csv")
        X_imp = df[['nox', 'masse_ordma_min', 'masse_ordma_max', 'nb_rapp', 'puiss_max']]

        # R√©encodage
        X_encoded_imp = pd.get_dummies(X_imp, dtype='int')

        # S√©paration des donn√©es en train et test
        X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_encoded_imp, y, test_size=0.2, random_state=12)

        # Standardisation
        scaler = StandardScaler()
        X_train_importances = scaler.fit_transform(X_train_imp)
        X_test_importances = scaler.transform(X_test_imp) 

        # R√©cup√©ration des donn√©es
        df=pd.read_csv("Donnees_propres.csv")
        df_caract = df[['carburant','hybride','masse_ordma_min','masse_ordma_max',
                "puiss_max",'Carrosserie','typ_boite','nb_rapp', 'gamme']]

        # R√©encodage
        df_caract['hybride'] = df_caract['hybride'].replace({'oui':1, 'non': 0})
        df_encoded_cara = pd.get_dummies(df_caract, dtype='int')

        # S√©paration des donn√©es en train et test
        X_train_cara, X_test_cara, y_train_cara, y_test_cara = train_test_split(df_encoded_cara, y, test_size=0.2, random_state=12)

        # Standardisation
        scaler = StandardScaler()
        X_train_scaled_cara = scaler.fit_transform(X_train_cara)
        X_test_scaled_cara = scaler.transform(X_test_cara) 


        # Dictionnaire des mod√®les sauvegard√©s
        models_dict = {
            "RandomForest (Donn√©es originales)": "Mod√®les_data1\RF_300",
            "XGBoost (Donn√©es originales)": "Mod√®les_data1\XGB",
            "RandomForest (SMOTE)": "Mod√®les_data1\RF_SMOTE",
            "XGBoost (Donn√©es SMOTE)": "Mod√®les_data1\XGB_smote",
            "RandomForest (Undersampling)": "Mod√®les_data1\RF_undersampling",
            "XGBoost (Undersampling)": "Mod√®les_data1\XGB_undersampling",
            "RandomForest (Variables plus importantes)": "Mod√®les_data1\RF_300_important",
            "RandomForest (Caract√©ristiques uniquement)": "Mod√®les_data1\RF_caracteristiques"         
             
        }

        # S√©lectionner le mod√®le via Streamlit
        selected_model_name = st.selectbox("Choisissez un mod√®le :", list(models_dict.keys()))

        # Charger le mod√®le s√©lectionn√©
        model_path = models_dict[selected_model_name]
        model = joblib.load(model_path)

        # Adapter les donn√©es en fonction du mod√®le choisi
        if "Variables plus importantes" in selected_model_name:
            X_train_selected = X_train_importances
            X_test_selected = X_test_importances
            y_train_selected = y_train_imp
            y_test_selected = y_test_imp
        elif "Caract√©ristiques uniquement" in selected_model_name:
            X_train_selected = X_train_scaled_cara
            X_test_selected = X_test_scaled_cara
            y_train_selected = y_train_cara
            y_test_selected = y_test_cara
        else:  # SMOTE, Undersampling et donn√©es originales
            X_train_selected = X_train_scaled  # Utilisation des X d'origine
            X_test_selected = X_test_scaled
            y_train_selected = y_train  # Cible correspondante
            y_test_selected = y_test

        # Pr√©dictions
        y_pred = model.predict(X_test_selected)

        # Calcul des m√©triques
        accuracy = accuracy_score(y_test_selected, y_pred)
        report = classification_report(y_test_selected, y_pred, output_dict=True)
        conf_matrix = confusion_matrix(y_test_selected, y_pred, normalize='true')

    # Affichage des r√©sultats
        st.write(f"#### R√©sultats pour : {selected_model_name}")
        st.write(f"**Accuracy :** {accuracy:.4f}")
        st.progress(int(accuracy * 100))  # Barre de progression pour l'accuracy

        # Pr√©parer les donn√©es pour le tableau (exclure les "avg" pour ne garder que les classes r√©elles)
        data = []
        for classe, valeurs in report.items():
            if isinstance(valeurs, dict):
                if 'avg' not in classe.lower():  # Exclure les moyennes 'avg'
                    f1_score = valeurs.get("f1-score", None)
                    support = valeurs.get("support", None)
                    precision = valeurs.get("precision", None)
                    recall = valeurs.get("recall", None)
                    if f1_score is not None:
                        data.append([classe,precision, recall, f1_score, support])

        # Cr√©er un DataFrame pour afficher les r√©sultats dans un tableau
        df_results = pd.DataFrame(data, columns=["Classe" , "Precision", "Recall", "F1-Score", "Support"])
        df_results = df_results.reset_index(drop=True)

        # Afficher le tableau avec Streamlit
        st.write("#### Scores par classe et autres m√©triques :")
        st.dataframe(df_results)
        
         # Affichage de la matrice de confusion avec une meilleure esth√©tique
        if st.button(" üîç Afficher la matrice de confusion", key = "selec_donnees"):
            st.write("#### Matrice de confusion normalis√©e :")
            conf_matrix_df = pd.DataFrame(conf_matrix, index=[f"Classe {i}" for i in range(len(conf_matrix))],
                              columns=[f"Classe {i}" for i in range(len(conf_matrix))])

            # Arrondir les valeurs de la matrice de confusion
            conf_matrix_df = conf_matrix_df.round(2)  # Arrondir √† 2 d√©cimales

            fig = px.imshow(conf_matrix_df, text_auto=True, aspect="auto", title="Matrice de confusion",
                    labels={'x': 'Pr√©dictions', 'y': 'Vraies valeurs'})
            fig.update_xaxes(side="top")
            st.plotly_chart(fig, key="conf_matrix_2")



        # Mod√®les de Deep Learning
        st.write('## 2. Deep Learning')
        import tensorflow as tf
        from tensorflow.keras.models import load_model
        import pickle



        # Dictionnaire des mod√®les enregistr√©s
        models_dict = {
        "MLP (Multi-Layer Perceptron)": "Mod√®les_data1\MLP.h5",
        "Mod√®le S√©quentiel (1 couche cach√©e)": "Mod√®les_data1\deep1.h5",
        "Mod√®le S√©quentiel (4 couches cach√©es + ReLU)": "Mod√®les_data1\Deep2.h5",
        "Mod√®le S√©quentiel (4 couches cach√©es + LeakyReLU)": "Mod√®les_data1\Deep3.h5",
        "Mod√®le S√©quentiel (4 couches + Dopout + batchnormalization + ReLU)": "Mod√®les_data1\Deep4.h5"
        }

        # S√©lection du mod√®le via Streamlit
        selected_model_name = st.selectbox("Choisissez un mod√®le :", list(models_dict.keys()))

        # Charger le mod√®le s√©lectionn√©
        model_path = models_dict[selected_model_name]
        model = load_model(model_path)

        # Faire les pr√©dictions
        test_pred = model.predict(X_test_scaled)
        test_pred_class = np.argmax(test_pred, axis=1)

        # Calculer les m√©triques
        report = classification_report(y_test, test_pred_class, output_dict=True)
        accuracy = report['accuracy']
        conf_matrix = confusion_matrix(y_test, test_pred_class, normalize='true').round(2)

    # Affichage des r√©sultats
        st.write(f"#### R√©sultats pour : {selected_model_name}")
        st.write(f"**Accuracy :** {accuracy:.4f}")
        st.progress(int(accuracy * 100))  # Barre de progression pour l'accuracy

        # Pr√©parer les donn√©es pour le tableau (exclure les "avg" pour ne garder que les classes r√©elles)
        data = []
        for classe, valeurs in report.items():
            if isinstance(valeurs, dict):
                if 'avg' not in classe.lower():  # Exclure les moyennes 'avg'
                    f1_score = valeurs.get("f1-score", None)
                    support = valeurs.get("support", None)
                    precision = valeurs.get("precision", None)
                    recall = valeurs.get("recall", None)
                    if f1_score is not None:
                        data.append([classe,precision, recall, f1_score, support])

        # Cr√©er un DataFrame pour afficher les r√©sultats dans un tableau
        df_results = pd.DataFrame(data, columns=["Classe" , "Precision", "Recall", "F1-Score", "Support"])
        df_results = df_results.reset_index(drop=True)

         # Affichage de la matrice de confusion avec une meilleure esth√©tique
        if st.button(" üîç Afficher la matrice de confusion", key = "mat_deep"):
            st.write("#### Matrice de confusion normalis√©e :")
            conf_matrix_df = pd.DataFrame(conf_matrix, index=[f"Classe {i}" for i in range(len(conf_matrix))],
                              columns=[f"Classe {i}" for i in range(len(conf_matrix))])

            # Arrondir les valeurs de la matrice de confusion
            conf_matrix_df = conf_matrix_df.round(2)  # Arrondir √† 2 d√©cimales

            fig = px.imshow(conf_matrix_df, text_auto=True, aspect="auto", title="Matrice de confusion",
                    labels={'x': 'Pr√©dictions', 'y': 'Vraies valeurs'})
            fig.update_xaxes(side="top")
            st.plotly_chart(fig, key="conf_matrix_3")

        # Charger l'historique du mod√®le s√©lectionn√©
        history_file = f"{model_path.split('.')[0]}_history.pkl"

        try:
            with open(history_file, "rb") as f:
                history = pickle.load(f)

            st.write(f"#### Evolution de l'accuracy en fonction des epochs :")
            plt.figure(figsize=(8, 5))
            plt.plot(history['accuracy'], label='Train Accuracy')
            plt.plot(history['val_accuracy'], label='Test Accuracy')
            plt.title(f"Evolution de l'accuracy pour : {selected_model_name}")
            plt.xlabel('Epochs')
            plt.ylabel('Accuracy')
            plt.legend()
            st.pyplot(plt)

        except FileNotFoundError:
            st.write("Pas d'historique disponible pour ce mod√®le.")


    # Charger le dataset 2
    if dataset_selector == dataset_select[1]:


        model_types = ["KNN", "RandomForest", "LogisticRegression", "SVM"]

        # Correspondance des mod√®les avec leurs pr√©fixes
        model_prefix = {
            "KNN": "KNN",
            "Random Forest": "RF",
            "Logistic Regression": "LR",
            "SVM": "SVM", 
            }

        features_order = ["conso", "puiss", "ec"]  # Les variables toujours dans cet ordre
    
        # üìå D√©finition des 7 variantes de mod√®les
        model_variants = {
            "conso_puiss_ec": ["conso", "puiss", "ec"],
            "conso_puiss": ["conso", "puiss"],
            "conso_ec": ["conso", "ec"],
            "conso": ["conso"],
            "puiss_ec": ["puiss", "ec"],
            "puiss": ["puiss"],
            "ec": ["ec"]
        }

        features_mapping = {
        "conso": "conso_mixte",
        "puiss": "puiss_max",
        "ec": "ec (cm3)"
        }

        # üìå Fonction pour charger le dataset propre
        @st.cache_data
        def load_data():
            df = pd.read_csv("data_merge_v2.csv")  
            return df

        df = load_data()

        # üìå Fonction pour charger un mod√®le et afficher son classification report
        def evaluate_model(model_name, variant):
            prefix = model_prefix[model_name]
            # Construire le chemin du fichier mod√®le (ex: "KNN_conso_puiss_ec.pkl")
            etude1 = "etude1/"
            model_path = etude1 + f"{prefix}_{variant}.pkl"

            # V√©rifier si le fichier existe avant de charger
            try:
                model = joblib.load(model_path)
            except FileNotFoundError:
                st.error(f"Le fichier {model_path} est introuvable.")
                return

            # S√©parer X et y en utilisant les variables dans l'ordre d√©fini
            #selected_features = [features_mapping["conso"], features_mapping["puiss"], features_mapping["ec"]]
            selected_features = [features_mapping[var] for var in model_variants[variant]]
            X = df[selected_features]
            y = df["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])

            # Diviser les donn√©es en train et test
            if prefix == "SVM" :
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            else :
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

            # üìå Appliquer le StandardScaler (sauvegard√© ou recalcul√©)
            scaler_path = f"scaler_{model_name}.pkl"  # Exemple : "scaler_KNN.pkl"
            try:
                scaler = joblib.load(scaler_path)
            except FileNotFoundError:
                scaler = StandardScaler().fit(X_train)  # ‚ö†Ô∏è Recalcul du scaler si non sauvegard√©

            X_test_scaled = scaler.transform(X_test)

            y_pred = model.predict(X_test_scaled)

            # G√©n√©rer le classification report
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()

            # Affichage dans Streamlit
            st.subheader(f"Classification Report - {model_name} ({variant})")
            st.dataframe(report_df.style.format(precision=3))

        # üìå Interface Streamlit
        st.title("√âvaluation des Mod√®les")

        # S√©lecteur de mod√®le
        selected_model = st.selectbox("Choisissez un mod√®le :", list(model_prefix.keys()))
        selected_variant = st.selectbox("Choisissez une variante :", list(model_variants.keys()))

        # Bouton pour ex√©cuter l'√©valuation
        if st.button("√âvaluer le mod√®le"):
            evaluate_model(selected_model, selected_variant)

        st.write('## Deuxi√®me √©tude - les caract√©ristiques de la voiture')

        @st.cache_data
        def load_data():
            df = pd.read_csv("data_merge_v2.csv") 
            df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
            df2["hybride"] = df2["hybride"].replace(to_replace=["non","oui"],value=[0,1])
            df2["category"] = df2["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])
            df2 = df2.loc[(df2["cod_cbr"] == "GO")| (df2["cod_cbr"] == "ES") | (df2["cod_cbr"] == "GH")].reset_index(drop=True)
            df2 = pd.get_dummies(df2)
            df = df2
            return df

        df = load_data()
        st.dataframe(df.head(5))

    
        model_paths = {
        "KNN Pas Optimis√©": "KNN_pas_optimise.pkl",
        "Random Forest Pas Optimis√©": "RF_pas_optimise.pkl"
        }

        def evaluate_optimized_model(model_name):
            #model_path = model_paths[model_name]
            base_path = "etude2/"
            model_path = base_path + f"{model_paths[model_name]}"


            # Charger le mod√®le
            model = joblib.load(model_path)

         # üìå S√©lectionner toutes les features sauf la cible
            X = df.drop(columns=["category"])  # Prend toutes les colonnes sauf la cible
            y = df["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])

            # Diviser les donn√©es en train et test
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # Appliquer le StandardScaler (sauvegard√© ou recalcul√©)
            scaler = StandardScaler().fit(X_train)  # ‚ö†Ô∏è Recalcul du scaler si non sauvegard√©

            X_train_scaled = scaler.transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # Calcul des scores
            train_score = model.score(X_train_scaled, y_train)
            test_score = model.score(X_test_scaled, y_test)

            # Affichage des scores dans Streamlit
            st.subheader(f"Scores - {model_name}")
            st.write(f"**Score d'entra√Ænement :** {train_score:.3f}")
            st.write(f"**Score de test :** {test_score:.3f}")

        # üìå Interface Streamlit
        st.title("√âvaluation des Mod√®les Pas Optimis√©s")

        # S√©lecteur de mod√®le
        selected_model = st.selectbox("Choisissez un mod√®le :", list(model_paths.keys()))

        # Bouton pour ex√©cuter l'√©valuation
        if st.button("√âvaluer le mod√®le", key='evaluate_button'):
            evaluate_optimized_model(selected_model)

        st.write('### Feature importance')
    
        base_path = "etude2/RF_pas_optimise.pkl"
        @st.cache_data
        def load_data():
            df = pd.read_csv("data_merge_v2.csv")
            # S√©lectionner les bonnes colonnes
            df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
        
            # Encodage des variables cat√©goriques
            df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
            df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
            df2 = pd.get_dummies(df2)

            return df2

        df = load_data()


        def display_feature_importance():
            # Charger le mod√®le
            model = joblib.load(base_path)

            # üìå V√©rifier la taille de feature_importances_
            nb_features_model = len(model.feature_importances_)

            # üìå R√©cup√©rer les features du dataset
            dataset_features = df.drop(columns=["category"]).columns.tolist()
            nb_features_dataset = len(dataset_features)

            # üìå V√©rifier la correspondance - mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
            #st.write(f"üìå Nombre de features dans le mod√®le : {nb_features_model}")
            #st.write(f"üìå Nombre de features dans le dataset : {nb_features_dataset}")

            # üìå Si la taille ne correspond pas, afficher la diff√©rence
            if nb_features_model != nb_features_dataset:
                # mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
                #st.error("‚ö†Ô∏è Probl√®me : Le nombre de features dans le dataset et le mod√®le ne correspond pas !") 

                # üìå V√©rifier quelles colonnes sont en trop ou manquantes
                features_manquantes = [f for f in dataset_features if f not in dataset_features[:nb_features_model]]
                features_suppl√©mentaires = dataset_features[nb_features_model:]

                # mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
                #st.write(f"üéØ Features manquantes dans le dataset : {features_manquantes}")
                #st.write(f"‚ö†Ô∏è Features suppl√©mentaires dans le dataset : {features_suppl√©mentaires}")

                # üìå Forcer la correspondance en prenant uniquement les premi√®res colonnes
                df_filtered = df[dataset_features[:nb_features_model]]
                #st.warning("‚ö†Ô∏è Alignement forc√© du dataset pour correspondre au mod√®le.")
            else:
                df_filtered = df[dataset_features]  # Les features correspondent d√©j√†

            # üìå V√©rifier que la taille correspond maintenant -  mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
            #st.write(f"‚úÖ Nouvelle taille des features dans Streamlit : {df_filtered.shape[1]}")
            #st.write(f"‚úÖ Taille des features dans le mod√®le : {nb_features_model}")

            # üìå R√©cup√©rer l'importance des features avec le dataset corrig√©
            feature_importances = model.feature_importances_
            importance_df = pd.DataFrame({
                "Feature": df_filtered.columns,
                "Importance": feature_importances
            })

            # üìå Trier par importance d√©croissante
            importance_df = importance_df.sort_values(by="Importance", ascending=False)

            # üìå Afficher les r√©sultats dans Streamlit
            st.write("### Importance des Features du Random Forest")
            st.dataframe(importance_df.style.format(precision=3))

            # üìå Afficher un graphique des 10 features les plus importantes
            plt.figure(figsize=(8, 6))
            plt.barh(importance_df["Feature"][:10], importance_df["Importance"][:10], color="skyblue")
            plt.xlabel("Importance")
            plt.ylabel("Feature")
            plt.title("Top 10 des Features Importantes")
            plt.gca().invert_yaxis()
            st.pyplot(plt)

        # üìå Interface Streamlit
        st.title("Analyse du Random Forest - Importance des Features")

        # Bouton pour afficher les importances
        if st.button("Afficher l'importance des features", key="feature_importance_button"):
            display_feature_importance()




        # üìå D√©finir les chemins des mod√®les
        base_path = "etude2/"
        knn_model_path = base_path + "KNN_pas_optimise.pkl"
        rf_model_path = base_path + "RF_pas_optimise.pkl"

        # üìå Charger le dataset
        @st.cache_data
        def load_data():
            dataset_path = "data_merge_v2.csv"  # Mets le bon chemin
            df = pd.read_csv(dataset_path)
        
            # S√©lectionner les bonnes colonnes
            df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
        
            # Encodage des variables cat√©goriques
            df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
            df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
            df2 = pd.get_dummies(df2)

            return df2

        df = load_data()

        if st.button("Charger les mod√®les et afficher les graphiques", key="btn_graphiques"):

            #   V√©rifier que les fichiers existent

            #  Charger les mod√®les apr√®s le clic sur le bouton
            knn_model = joblib.load(knn_model_path)
            rf_model = joblib.load(rf_model_path)

            #  G√©n√©rer les listes de performance pour les graphiques
            importance_list = list(df.drop(columns=["category"]).columns)  # Features disponibles

            list_knn_train = []
            list_knn_test = []
            list_rf_train = []
            list_rf_test = []

            for i in range(len(importance_list)):
                importance_sous_list = importance_list[:i+1]

                X = df[importance_sous_list]
                y = df["category"]

                #  Split des donn√©es
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

                #  Standardisation
                scaler = StandardScaler().fit(X_train)
                X_train_scaled = scaler.transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                #  √âvaluation du mod√®le KNN
                knn_model.fit(X_train_scaled, y_train)
                list_knn_train.append(knn_model.score(X_train_scaled, y_train))
                list_knn_test.append(knn_model.score(X_test_scaled, y_test))

                #  √âvaluation du mod√®le Random Forest
                rf_model.fit(X_train_scaled, y_train)
                list_rf_train.append(rf_model.score(X_train_scaled, y_train))
                list_rf_test.append(rf_model.score(X_test_scaled, y_test))

            #  Graphique pour KNN
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(list_knn_train, label="KNN Train", color='purple')
            ax.plot(list_knn_test, label="KNN Test", color="orange")
            ax.set_title("Performance du KNN")
            ax.legend()
            ax.set_xticks(range(len(importance_list)))
            ax.set_xticklabels(importance_list, rotation=80)
            st.pyplot(fig)

            #  Graphique pour Random Forest
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(list_rf_train, label="Random Forest Train", color='blue')
            ax.plot(list_rf_test, label="Random Forest Test", color="green")
            ax.set_title("Performance du Random Forest")
            ax.legend()
            ax.set_xticks(range(len(importance_list)))
            ax.set_xticklabels(importance_list, rotation=80)
            st.pyplot(fig)




        # üìå D√©finir le r√©pertoire des fichiers mod√®les
        save_dir = "etude3/"

        # üìå V√©rifier si les fichiers mod√®les existent
        model_files = ["KNN_smote.pkl", "RF_smote.pkl", "scaler.pkl", "features.pkl"]


        # üìå Charger les mod√®les et transformations
        knn = joblib.load(save_dir+ "KNN_smote.pkl")
        rforest = joblib.load(save_dir+  "RF_smote.pkl")
        scaler = joblib.load(save_dir+  "scaler.pkl")
        model_features = joblib.load(save_dir+  "features.pkl")
    

        # üìå Charger le dataset
        @st.cache_data
        def load_data():
            df = pd.read_csv("data_merge_v2.csv")

            # S√©lectionner les bonnes colonnes
            df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]

            # Encodage des variables cat√©goriques
            df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
            df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
            df2 = pd.get_dummies(df2)

            # S'assurer que toutes les features correspondent au mod√®le
            for feature in model_features:
                if feature not in df2.columns:
                    df2[feature] = 0  # Ajouter les colonnes manquantes avec des valeurs nulles

            # R√©organiser les colonnes pour correspondre au mod√®le
            df2 = df2[["category"] + model_features]

            return df2

        df = load_data()

        # üìå S√©parer X et y
        X = df.drop(columns=["category"])
        y = df["category"]

        # üìå Split des donn√©es (m√™me split que lors de l'entra√Ænement)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

        # üìå Appliquer le StandardScaler d√©j√† entra√Æn√©
        X_train_scaled = scaler.transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # üìå Calculer les scores sans refaire `fit()`
        knn_train_score = knn.score(X_train_scaled, y_train)  # Utiliser le scaler charg√©
        knn_test_score = knn.score(X_test_scaled, y_test)

        rf_train_score = rforest.score(X_train_scaled, y_train)
        rf_test_score = rforest.score(X_test_scaled, y_test)

        # üìå Afficher les r√©sultats dans Streamlit
        st.subheader("R√©sultats du Mod√®le KNN (Charg√©)")
        st.write(f"üîπ **Score d'entra√Ænement :** {knn_train_score:.3f}")
        st.write(f"üîπ **Score de test :** {knn_test_score:.3f}")

        st.subheader("R√©sultats du Mod√®le Random Forest (Charg√©)")
        st.write(f"üîπ **Score d'entra√Ænement :** {rf_train_score:.3f}")
        st.write(f"üîπ **Score de test :** {rf_test_score:.3f}")




        st.write("## Mod√®le de Deep Learning")
        save_dir = "deep_learning/"

        # üìå Charger `train_data.pkl` contenant X_train_scal√© et y_train
        train_data_path = os.path.join(save_dir, "train_data.pkl")

        if os.path.exists(train_data_path):
            train_data = joblib.load(train_data_path)

            if "feature_names" not in train_data:
                st.error("‚ùå `feature_names` est absent de `train_data.pkl`. V√©rifie que le fichier a √©t√© sauvegard√© correctement.")
                st.stop()

            X_train_scaled = train_data["X_train"]
            y_train = train_data["y_train"]
            feature_names = train_data["feature_names"]

            # üìå V√©rification des tailles
            if X_train_scaled.shape[0] != y_train.shape[0]:
                st.error(f"‚ùå ERREUR : `X_train_scaled` ({X_train_scaled.shape[0]}) et `y_train` ({y_train.shape[0]}) n'ont pas la m√™me taille !")
                st.stop()

            # ‚úÖ V√©rifier que X_train_scaled n'a pas √©t√© modifi√©
            assert X_train_scaled.shape == (1910, 753), "‚ùå ERREUR : `X_train_scaled` a √©t√© modifi√© par erreur !"

        else:
            st.error("‚ùå `train_data.pkl` est introuvable.")
            st.stop()

        # üìå Charger les donn√©es de test
        @st.cache_data
        def load_data():
            df = pd.read_csv("data_merge_v2.csv")
            df_X = df.drop(['category', 'conso_urb', 'conso_exurb', 'conso_mixte', 'co2', 'co_typ_1', 'nox', 'ptcl'], axis=1, errors='ignore')
            df_X = pd.get_dummies(df_X, dtype='int')

            missing_features = [feat for feat in feature_names if feat not in df_X.columns]
            extra_features = [feat for feat in df_X.columns if feat not in feature_names]

            for feature in missing_features:
                df_X[feature] = 0

            df_X = df_X[feature_names]
            df_y = df['category'].replace(to_replace=['A','B','C','D','E','F','G'], value=[0,1,2,3,4,5,6])

            return df_X, df_y

        X_test, y_test = load_data()

        # üìå Charger le StandardScaler
        scaler = joblib.load(os.path.join(save_dir, "scaler.pkl"))
        X_test_scaled = scaler.transform(X_test)

        # üìå V√©rification des dimensions
        st.write("üîç **V√©rification des dimensions avant ex√©cution du mod√®le :**")
        st.write(f"üìå X_train_scaled shape : {X_train_scaled.shape}")
        st.write(f"üìå y_train shape : {y_train.shape}")
        st.write(f"üìå X_test_scaled shape : {X_test_scaled.shape}")
        st.write(f"üìå y_test shape : {y_test.shape}")

        # üìå Bouton pour ex√©cuter le mod√®le
        if st.button("Ex√©cuter le mod√®le de Deep Learning"):

            # üìå Charger le mod√®le
            deep_model = load_model(os.path.join(save_dir, "deep_model.h5"))

            # üìå V√©rifier la correspondance entre `X_test_scaled` et le mod√®le
            expected_input_shape = deep_model.input_shape[1]
            actual_input_shape = X_test_scaled.shape[1]

            if expected_input_shape != actual_input_shape:
                st.error(f"‚ùå ERREUR : Le mod√®le attend {expected_input_shape} features, mais `X_test_scaled` en a {actual_input_shape} !")
                st.stop()

            # üìå V√©rifier si les donn√©es sont bien normalis√©es
            st.write("üîç **V√©rification de la normalisation de X_train_scaled et X_test_scaled :**")
            st.write("üìå Moyenne et √©cart-type AVANT normalisation (X_train) :")
            st.write(pd.DataFrame(X_train_scaled).describe())

            st.write("üìå Moyenne et √©cart-type APR√àS normalisation (X_test_scaled) :")
            st.write(pd.DataFrame(X_test_scaled).describe())

            # üìå Faire des pr√©dictions
            y_pred_proba = deep_model.predict(X_test_scaled)
            y_pred = np.argmax(y_pred_proba, axis=1)

            # üìå Calculer les scores
            test_accuracy = np.mean(y_pred == y_test)
            train_accuracy = deep_model.evaluate(X_train_scaled, y_train, verbose=0)[1]

            # üìå Afficher les r√©sultats
            st.subheader("R√©sultats du Mod√®le Deep Learning")
            st.write(f"üîπ **Score d'entra√Ænement :** {train_accuracy:.3f}")
            st.write(f"üîπ **Score de test :** {test_accuracy:.3f}")

            # üìå Afficher les pr√©dictions
            predictions_df = pd.DataFrame({"Actual": y_test, "Predicted": y_pred})
            st.dataframe(predictions_df)

            st.success("‚úÖ Mod√®le Deep Learning charg√© et √©valu√© avec succ√®s !")
