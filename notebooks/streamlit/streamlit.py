import streamlit as st
import os
import io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

from imblearn.over_sampling import SMOTE

import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler

st.title("DS Octobre - Projet CO2")
st.sidebar.title('Sommaire')
pages=['Introduction', 'Exploration', 'Mod√©lisation']
page = st.sidebar.radio('Aller vers', pages)


# premier onglet - introduction au projet
if page == pages[0] : 
    st.write('# Introduction')
    st.write("Le changement climatique est l‚Äôun des d√©fis majeurs du XXIe si√®cle, et la r√©duction des √©missions de CO‚ÇÇ est un enjeu central dans la lutte contre le r√©chauffement global. Parmi les secteurs les plus polluants, le transport joue un r√¥le cl√© : en 2019, il √©tait responsable d‚Äôenviron un quart des √©missions totales de CO‚ÇÇ de l‚ÄôUnion europ√©enne, dont 71,7 % provenaient du transport routier. Les voitures personnelles, en particulier, repr√©sentaient 60,6% des √©missions de CO‚ÇÇ li√©es √† ce secteur."
             "Malgr√© les efforts pour limiter ces √©missions, on observe une augmentation de 33,5 % entre 1990 et 2019. Selon les projections actuelles, la diminution des √©missions du transport d‚Äôici 2050 ne serait que de 22 %, bien en de√ß√† des objectifs n√©cessaires pour respecter les engagements climatiques."
             "Face √† cette probl√©matique, deux principales strat√©gies permettent de r√©duire l‚Äôempreinte carbone des v√©hicules : am√©liorer leur efficacit√© √©nerg√©tique et modifier leur source d‚Äô√©nergie, en passant par exemple √† des carburants alternatifs ou √† l‚Äô√©lectrification."
             "Dans ce contexte, notre projet vise √† pr√©dire les √©missions de CO‚ÇÇ des v√©hicules en fonction de leurs caract√©ristiques. En d√©veloppant un mod√®le de pr√©diction pr√©cis, nous pourrions contribuer √† mieux comprendre les facteurs influen√ßant ces √©missions et ainsi aider les constructeurs √† voir comment optimiser leurs prochaines s√©ries de voiture lorsque ceux-ci sont soucieux de leur impact environnemental."
             "")
    st.image("images\image1.png")
    st.write('## Identification de la probl√©matique')
    url1 = 'https://www.data.gouv.fr/fr/datasets/emissions-de-co2-et-de-polluants-des-vehicules-commercialises-en-france/#_'
    url2 = 'https://co2cars.apps.eea.europa.eu/?source=%7B%22track_total_hits%22%3Atrue%2C%22query%22%3A%7B%22bool%22%3A%7B%22must%22%3A%5B%7B%22constant_score%22%3A%7B%22filter%22%3A%7B%22bool%22%3A%7B%22must%22%3A%5B%7B%22bool%22%3A%7B%22should%22%3A%5B%7B%22term%22%3A%7B%22year%22%3A2014%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2013%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2012%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2011%7D%7D%2C%7B%22term%22%3A%7B%22year%22%3A2010%7D%7D%5D%7D%7D%2C%7B%22bool%22%3A%7B%22should%22%3A%5B%7B%22term%22%3A%7B%22scStatus%22%3A%22Final%22%7D%7D%5D%7D%7D%5D%7D%7D%7D%7D%5D%7D%7D%2C%22display_type%22%3A%22tabular%22%7D'

    st.write("Nous sommes partis des donn√©es disponibles sur le site [data.gouv.fr](%s)" % url1 , " qui contiennent les √©missions des CO2 et les caract√©ristiques des v√©hicules commercialis√©s en France en 2014. "
             "Nous avons √©galement trouv√© des donn√©es int√©ressantes de [l'Agence europ√©enne pour l'environnement](%s)" % url2 , " qui viennent compl√©ter certaines informations manquantes au premier jeu de donn√©es."
             "Nous avons √† faire √† une probl√©matique de classification supervis√©e. A partir de leurs caract√©ristiques, nous cherchons √† classer les v√©hicules selon les 7 cat√©gories d‚Äô√©mission de C02 en nous basant sur l‚Äô√©tiquette √©nerg√©tique des v√©hicules. "
             "")
    st.image("images\image2.png")
    st.write("Notre variable cible est d√©j√† pr√©sente dans le jeu de donn√©es, c‚Äôest la variable co2. Nous transformerons cette variable, actuellement quantitative, en une variable cat√©gorielle pour plus de visibilit√© lors de la transmission des r√©sultats.")

# deuxi√®me onglet - exploration de nos datasets
if page == pages[1] :
    st.write('# Exploration')

    # selection du dataset explor√©
    dataset_select = ['Dataset #1', 'Dataset Merge']
    dataset_selector = st.radio('Choix du dataset', dataset_select)

    if dataset_selector == dataset_select[0] :
        df=pd.read_csv("mars-2014-complete.csv",encoding='ISO-8859-1', sep = ';')
        st.write('## Dataset #1')
        df=pd.read_csv("mars-2014-complete.csv",encoding='ISO-8859-1', sep = ';')

        st.write('### Pr√©sentation des donn√©es avant nettoyage')
        # Affichage des informations g√©n√©rales du DataFrame
        st.dataframe(pd.DataFrame({
        "Colonnes": df.columns,
        "Type": df.dtypes,
        "Valeurs Manquantes": df.isna().sum(),
        "Nb. Valeurs Uniques": df.nunique()
        }))

        st.dataframe(pd.DataFrame({"Dimension": ["Lignes", "Colonnes"], "Valeur": df.shape}))
        
        # Affichage des 3 premi√®res lignes du DataFrame
        st.dataframe(df.head(5))

        st.write('### S√©lection des variables')
        st.write(""" Nous nous int√©ressons d‚Äôabord au pourcentage de valeurs manquantes. Les variables hc et date_maj en contiennent plus de 80%. Nous d√©cidons donc de supprimer ces variables. 

    La variable hcnox √©tant directement reli√©e √† la variable hc, nous d√©cidons de la supprimer √©galement.

    La variable ptcl contient 5% de donn√©es manquantes. Apr√®s avoir regard√© la proportion de ces donn√©es manquantes en fonction de la marque de voiture, nous avons pu voir que la majorit√© des donn√©es manquantes proviennent de la marque Mercedes qui est une classe largement majoritaire dans notre jeu de donn√©es. Garder cette variable en ne supprimant que les lignes contenant des valeurs manquantes nous para√Æt donc pertinent puisque nous ne perdons pas beaucoup d'informations.

    Les variables cnit (Code National d‚ÄôIdentification du Type) et tvv (Type Variante Version) sont des variables qui correspondent √† des ID d‚Äôidentification. Ainsi ces variables ne sont pas n√©cessaires comme variables explicatives pour le mod√®le, mais elles peuvent √™tre utiles comme clef pour lier et fusionner ce dataset avec d‚Äôautres dataset (Voir plus tard).

    La variable co2 est utile pour cr√©er notre variable cible. Elle renseigne la quantit√© d‚Äô√©mission de CO2 en g/km. Lorsque l‚Äôon regarde les √©tiquettes de pollution, les diff√©rentes cat√©gories se basent sur cette donn√©e. Ainsi on cr√©e une nouvelle variable que l‚Äôon nomme Category dont la valeur est d√©termin√©e √† partir de l‚Äôimage ci-dessous. Cette variable sera notre variable cible pour notre probl√®me de classification.

    Les variables puiss_max, conso_urb, conso_exurb, conso_mixte, co_typ_1, nox et ptcl sont initialement des cha√Ænes de caract√®res. Cependant, ce sont des variables quantitatives dans les faits. Ainsi, il est n√©cessaire de changer leur type pour avoir des flottants.
    Toutes les autres variables pas encore mentionn√©es sont conserv√©es. Cela repr√©sente des variables cat√©gorielles ou des variables quantitatives qui nous semblent pertinentes comme variables explicatives pour le mod√®le. Nous verrons un peu plus en d√©tail chacune de ces variables, leurs modes pour les variables cat√©gorielles et leur r√©partition pour les variables quantitatives. 
    """)
        
        st.write('### Gestion des valeurs manquantes')
        st.write("""Pour les variables conserv√©es, √©tant donn√© que le nombre de valeurs manquantes repr√©sente un pourcentage faible de l'enti√®ret√© des valeurs du dataset, on a d√©cid√© de supprimer la ligne s'il manquait au moins une valeur. On ne perd pas √©norm√©ment d‚Äô√©chantillons en appliquant cette strat√©gie. On pr√©f√®re supprimer l‚Äôindividu plut√¥t que de remplacer une valeur manquante par le mode le plus pr√©sent ou la m√©diane car cette nouvelle valeur reste hypoth√©tique.  """)
        
        # nettoyage du dataset1
        #
        df = df.iloc[:, :-4]
        to_drop = ["cnit", "tvv", "hc", "hcnox", "date_maj"]
        df_clear = df.drop(to_drop, axis = 1)
        df_without_Na = df_clear.dropna()
        quantitative_col = ["co2","puiss_admin_98","puiss_max","conso_urb","conso_exurb","conso_mixte","co_typ_1","nox","ptcl","masse_ordma_min","masse_ordma_max"]
        df_quantitative = df_without_Na[quantitative_col]

        for name in df_quantitative:
            # Remplacement des virgules par des points et changement de type
            df_without_Na[name] = pd.to_numeric(df_without_Na[name].astype(str).str.replace(',', '.'), errors = 'coerce')
            df_quantitative[name] = pd.to_numeric(df_without_Na[name].astype(str).str.replace(',', '.'), errors = 'coerce')
        
        df_without_Na['typ_boite'] = None 
        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('M'), 'typ_boite'] = 'Manuelle'

        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('A'), 'typ_boite'] = 'Auto'

        df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.startswith('V'), 'typ_boite'] = 'Var_continue'

        # On supprime les Nan cr√©√©es
        df_without_Na = df_without_Na.dropna(subset=['typ_boite'])
 
        df_without_Na['nb_rapp'] = None 

        list_vitesse = ['0','5', '6', '7', '8', '9']

        for i in list_vitesse:
            df_without_Na.loc[df_without_Na['typ_boite_nb_rapp'].str.contains(i), 'nb_rapp'] = i

        # On supprimer les Nan cr√©√©es
        df_without_Na = df_without_Na.dropna(subset=['nb_rapp'])

        rapport_counts = df_without_Na['nb_rapp'].value_counts()

        #ajout des √©tiquettes
        bins = [0, 100, 120, 140, 160, 200, 250, float('inf')]
        labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G']

        df_without_Na['category'] = pd.cut(df_without_Na['co2'], bins=bins, labels=labels, right=True)

        #fin du nettoyage
        #


        st.write('### Analyse des variables')

        fig, ax = plt.subplots()
        sns.boxplot(data=df_without_Na, x='cod_cbr', y='co2', palette="viridis", ax=ax)
        plt.xticks(rotation=45, fontsize=10, ha='right')
        plt.xlabel('Type de carburant', fontsize=12)
        plt.ylabel('√âmission de CO2', fontsize=12)
        plt.title('Distribution du CO2 par type de carburant', fontsize=14)
        st.pyplot(fig)

        fig, ax = plt.subplots()
        sns.scatterplot(x="puiss_max", y="co2", data=df_without_Na, hue="gamme", ax=ax)
        plt.xlabel("Puissance max")
        plt.ylabel("CO2")
        plt.title("Co2 en fonction de la puissance max et de la gamme du v√©hicule")
        st.pyplot(fig)

        # plot c√¥te √† c√¥te
        fig, axes = plt.subplots(ncols=2, figsize=(12, 5))
        # Barplot du type de boite
        sns.countplot(data=df_without_Na, x='typ_boite', palette="viridis", ax=axes[0])
        axes[0].set_xlabel('Type de boite de vitesse', fontsize=12)
        axes[0].set_ylabel('Count', fontsize=12)
        axes[0].set_title('R√©partition des boites de vitesses', fontsize=14)

        # Barplot du nombre de rapports
        sns.countplot(data=df_without_Na, x='nb_rapp', palette="viridis", ax=axes[1])
        axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, fontsize=10, ha='right')
        axes[1].set_xlabel('Nombre de rapports', fontsize=12)
        axes[1].set_ylabel('Count', fontsize=12)
        axes[1].set_title('R√©partition des nombres de rapports', fontsize=14)
        st.pyplot(fig)
        
        # plot c√¥te √† c√¥te
        fig, axes = plt.subplots(ncols=2, figsize=(12, 5))
        sns.boxplot(data=df_without_Na, x='typ_boite', y='co2', palette="viridis", ax=axes[0])
        axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, fontsize=10, ha='right')  
        axes[0].set_xlabel('Boites de vitesse', fontsize=12)
        axes[0].set_ylabel('CO2', fontsize=12)
        axes[0].set_title('CO2 en fonction du type de boite de vitesse', fontsize=14) 

        # Boxplot : Nombre de vitesses vs CO2
        sns.boxplot(data=df_without_Na, x='nb_rapp', y='co2', palette="viridis", ax=axes[1])
        axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, fontsize=10, ha='right')  
        axes[1].set_xlabel('Nombre de vitesses', fontsize=12)
        axes[1].set_ylabel('CO2', fontsize=12)
        axes[1].set_title('CO2 en fonction du nombre de vitesses', fontsize=14) 
        st.pyplot(fig)

        fig = plt.figure()
        sns.countplot(data=df_without_Na, x ='category', palette="viridis")
        plt.xticks(rotation=45, fontsize=10, ha='right')  
        plt.xlabel('Etiquette', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title("R√©partition des cat√©gories d'emission de CO2", fontsize=14) 
        plt.tight_layout()
        st.pyplot(fig)

        fig = plt.figure()
        sns.countplot(data=df_without_Na, x ='Carrosserie', palette="viridis")
        plt.xticks(rotation=45, fontsize=10, ha='right')  
        plt.xlabel('Carosserie', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title('R√©partition des carosserie', fontsize=14) 
        st.pyplot(fig)

        fig = plt.figure()
        sns.countplot(data=df_without_Na, x ='gamme', palette="viridis")
        plt.xticks(rotation=45, fontsize=10, ha='right')  
        plt.xlabel('Gamme', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title('R√©partition des gammes', fontsize=14) 
        st.pyplot(fig)
    
    
    if dataset_selector == dataset_select[1] :
        df=pd.read_csv("data_merge_v2.csv")
        st.write('## Description du merge')
        st.image("images\Schema merge.png")

        st.write('## Dataset Merge')
        st.dataframe(df.head(5))

        
        fig = plt.figure()
        sns.boxplot(y=df["ec (cm3)"])
        plt.title('R√©partion des valeurs cylindr√©s des moteurs (Ec (cm3))')
        st.pyplot(fig)
        
        fig = plt.figure()
        sns.boxplot(y=df["W (mm)"])
        plt.title('R√©partition des valeurs du diam√®tres des roues (W (mm))')
        st.pyplot(fig)

        fig = plt.figure()
        sns.scatterplot(data=df, x='ec (cm3)', y='puiss_max', hue='category')
        plt.xlabel("Engine Capacity")
        plt.ylabel("Puissance maximale")
        plt.title("La puissance maximale en fonction de capacit√© du moteur pour chaque cat√©gorie d'√©mission de CO2")
        st.pyplot(fig)


if page == pages[2] :
    st.write('# Mod√©lisation')
    st.write('## Dataset Merge')


    model_types = ["KNN", "RandomForest", "LogisticRegression", "SVM"]

    # Correspondance des mod√®les avec leurs pr√©fixes
    model_prefix = {
        "KNN": "KNN",
        "Random Forest": "RF",
        "Logistic Regression": "LR",
        "SVM": "SVM", 
        }

    features_order = ["conso", "puiss", "ec"]  # Les variables toujours dans cet ordre
    
    # üìå D√©finition des 7 variantes de mod√®les
    model_variants = {
        "conso_puiss_ec": ["conso", "puiss", "ec"],
        "conso_puiss": ["conso", "puiss"],
        "conso_ec": ["conso", "ec"],
        "conso": ["conso"],
        "puiss_ec": ["puiss", "ec"],
        "puiss": ["puiss"],
        "ec": ["ec"]
    }

    features_mapping = {
    "conso": "conso_mixte",
    "puiss": "puiss_max",
    "ec": "ec (cm3)"
    }

    # üìå Fonction pour charger le dataset initial
    @st.cache_data
    def load_data():
        df = pd.read_csv("data_merge_v2.csv")  
        return df

    df = load_data()

    # üìå Fonction pour charger un mod√®le et afficher son classification report
    def evaluate_model(model_name, variant):
        prefix = model_prefix[model_name]
        # Construire le chemin du fichier mod√®le (ex: "KNN_conso_puiss_ec.pkl")
        etude1 = "etude1/"
        model_path = etude1 + f"{prefix}_{variant}.pkl"

        # V√©rifier si le fichier existe avant de charger
        try:
            model = joblib.load(model_path)
        except FileNotFoundError:
            st.error(f"Le fichier {model_path} est introuvable.")
            return

        # S√©parer X et y en utilisant les variables dans l'ordre d√©fini
        #selected_features = [features_mapping["conso"], features_mapping["puiss"], features_mapping["ec"]]
        selected_features = [features_mapping[var] for var in model_variants[variant]]
        X = df[selected_features]
        y = df["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])

        # Diviser les donn√©es en train et test
        if prefix == "SVM" :
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        else :
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

        # üìå Appliquer le StandardScaler (sauvegard√© ou recalcul√©)
        scaler_path = f"scaler_{model_name}.pkl"  # Exemple : "scaler_KNN.pkl"
        try:
            scaler = joblib.load(scaler_path)
        except FileNotFoundError:
            scaler = StandardScaler().fit(X_train)  # ‚ö†Ô∏è Recalcul du scaler si non sauvegard√©

        X_test_scaled = scaler.transform(X_test)

        y_pred = model.predict(X_test_scaled)

        # G√©n√©rer le classification report
        report = classification_report(y_test, y_pred, output_dict=True)
        report_df = pd.DataFrame(report).transpose()

        # Affichage dans Streamlit
        st.subheader(f"Classification Report - {model_name} ({variant})")
        st.dataframe(report_df.style.format(precision=3))

    # üìå Interface Streamlit
    st.title("√âvaluation des Mod√®les")

    # S√©lecteur de mod√®le
    selected_model = st.selectbox("Choisissez un mod√®le :", list(model_prefix.keys()))
    selected_variant = st.selectbox("Choisissez une variante :", list(model_variants.keys()))

    # Bouton pour ex√©cuter l'√©valuation
    if st.button("√âvaluer le mod√®le"):
        evaluate_model(selected_model, selected_variant)

    st.write('## Deuxi√®me √©tude - les caract√©ristiques de la voiture')

    @st.cache_data
    def load_data():
        df = pd.read_csv("data_merge_v2.csv") 
        df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
        df2["hybride"] = df2["hybride"].replace(to_replace=["non","oui"],value=[0,1])
        df2["category"] = df2["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])
        df2 = df2.loc[(df2["cod_cbr"] == "GO")| (df2["cod_cbr"] == "ES") | (df2["cod_cbr"] == "GH")].reset_index(drop=True)
        df2 = pd.get_dummies(df2)
        df = df2
        return df

    df = load_data()
    st.dataframe(df.head(5))

    
    model_paths = {
    "KNN Pas Optimis√©": "KNN_pas_optimise.pkl",
    "Random Forest Pas Optimis√©": "RF_pas_optimise.pkl"
    }

    def evaluate_optimized_model(model_name):
        #model_path = model_paths[model_name]
        base_path = "etude2/"
        model_path = base_path + f"{model_paths[model_name]}"


        # Charger le mod√®le
        model = joblib.load(model_path)

        # üìå S√©lectionner toutes les features sauf la cible
        X = df.drop(columns=["category"])  # Prend toutes les colonnes sauf la cible
        y = df["category"].replace(to_replace=['A','B','C','D','E','F','G'],value=[0,1,2,3,4,5,6])

        # Diviser les donn√©es en train et test
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Appliquer le StandardScaler (sauvegard√© ou recalcul√©)
        scaler = StandardScaler().fit(X_train)  # ‚ö†Ô∏è Recalcul du scaler si non sauvegard√©

        X_train_scaled = scaler.transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Calcul des scores
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)

        # Affichage des scores dans Streamlit
        st.subheader(f"Scores - {model_name}")
        st.write(f"**Score d'entra√Ænement :** {train_score:.3f}")
        st.write(f"**Score de test :** {test_score:.3f}")

    # üìå Interface Streamlit
    st.title("√âvaluation des Mod√®les Pas Optimis√©s")

    # S√©lecteur de mod√®le
    selected_model = st.selectbox("Choisissez un mod√®le :", list(model_paths.keys()))

    # Bouton pour ex√©cuter l'√©valuation
    if st.button("√âvaluer le mod√®le", key='evaluate_button'):
        evaluate_optimized_model(selected_model)

    st.write('### Feature importance')
    
    base_path = "etude2/RF_pas_optimise.pkl"
    @st.cache_data
    def load_data():
        df = pd.read_csv("data_merge_v2.csv")
        # S√©lectionner les bonnes colonnes
        df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
        
        # Encodage des variables cat√©goriques
        df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
        df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
        df2 = pd.get_dummies(df2)

        return df2

    df = load_data()


    def display_feature_importance():
        # Charger le mod√®le
        model = joblib.load(base_path)

        # üìå V√©rifier la taille de feature_importances_
        nb_features_model = len(model.feature_importances_)

        # üìå R√©cup√©rer les features du dataset
        dataset_features = df.drop(columns=["category"]).columns.tolist()
        nb_features_dataset = len(dataset_features)

        # üìå V√©rifier la correspondance - mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
        #st.write(f"üìå Nombre de features dans le mod√®le : {nb_features_model}")
        #st.write(f"üìå Nombre de features dans le dataset : {nb_features_dataset}")

        # üìå Si la taille ne correspond pas, afficher la diff√©rence
        if nb_features_model != nb_features_dataset:
            # mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
            #st.error("‚ö†Ô∏è Probl√®me : Le nombre de features dans le dataset et le mod√®le ne correspond pas !") 

            # üìå V√©rifier quelles colonnes sont en trop ou manquantes
            features_manquantes = [f for f in dataset_features if f not in dataset_features[:nb_features_model]]
            features_suppl√©mentaires = dataset_features[nb_features_model:]

            # mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
            #st.write(f"üéØ Features manquantes dans le dataset : {features_manquantes}")
            #st.write(f"‚ö†Ô∏è Features suppl√©mentaires dans le dataset : {features_suppl√©mentaires}")

            # üìå Forcer la correspondance en prenant uniquement les premi√®res colonnes
            df_filtered = df[dataset_features[:nb_features_model]]
            #st.warning("‚ö†Ô∏è Alignement forc√© du dataset pour correspondre au mod√®le.")
        else:
            df_filtered = df[dataset_features]  # Les features correspondent d√©j√†

        # üìå V√©rifier que la taille correspond maintenant -  mis en commentaire pour masquer les erreur, utiles pour le troubleshooting
        #st.write(f"‚úÖ Nouvelle taille des features dans Streamlit : {df_filtered.shape[1]}")
        #st.write(f"‚úÖ Taille des features dans le mod√®le : {nb_features_model}")

        # üìå R√©cup√©rer l'importance des features avec le dataset corrig√©
        feature_importances = model.feature_importances_
        importance_df = pd.DataFrame({
            "Feature": df_filtered.columns,
            "Importance": feature_importances
        })

        # üìå Trier par importance d√©croissante
        importance_df = importance_df.sort_values(by="Importance", ascending=False)

        # üìå Afficher les r√©sultats dans Streamlit
        st.write("### Importance des Features du Random Forest")
        st.dataframe(importance_df.style.format(precision=3))

        # üìå Afficher un graphique des 10 features les plus importantes
        plt.figure(figsize=(8, 6))
        plt.barh(importance_df["Feature"][:10], importance_df["Importance"][:10], color="skyblue")
        plt.xlabel("Importance")
        plt.ylabel("Feature")
        plt.title("Top 10 des Features Importantes")
        plt.gca().invert_yaxis()
        st.pyplot(plt)

    # üìå Interface Streamlit
    st.title("Analyse du Random Forest - Importance des Features")

    # Bouton pour afficher les importances
    if st.button("Afficher l'importance des features", key="feature_importance_button"):
        display_feature_importance()




    # üìå D√©finir les chemins des mod√®les
    base_path = "etude2/"
    knn_model_path = base_path + "KNN_pas_optimise.pkl"
    rf_model_path = base_path + "RF_pas_optimise.pkl"

    # üìå Charger le dataset
    @st.cache_data
    def load_data():
        dataset_path = "data_merge_v2.csv"  # Mets le bon chemin
        df = pd.read_csv(dataset_path)
        
        # S√©lectionner les bonnes colonnes
        df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]
        
        # Encodage des variables cat√©goriques
        df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
        df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
        df2 = pd.get_dummies(df2)

        return df2

    df = load_data()

    if st.button("Charger les mod√®les et afficher les graphiques", key="btn_graphiques"):

        #  V√©rifier que les fichiers existent

        #  Charger les mod√®les apr√®s le clic sur le bouton
        knn_model = joblib.load(knn_model_path)
        rf_model = joblib.load(rf_model_path)

        #  G√©n√©rer les listes de performance pour les graphiques
        importance_list = list(df.drop(columns=["category"]).columns)  # Features disponibles

        list_knn_train = []
        list_knn_test = []
        list_rf_train = []
        list_rf_test = []

        for i in range(len(importance_list)):
            importance_sous_list = importance_list[:i+1]

            X = df[importance_sous_list]
            y = df["category"]

            #  Split des donn√©es
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

            #  Standardisation
            scaler = StandardScaler().fit(X_train)
            X_train_scaled = scaler.transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            #  √âvaluation du mod√®le KNN
            knn_model.fit(X_train_scaled, y_train)
            list_knn_train.append(knn_model.score(X_train_scaled, y_train))
            list_knn_test.append(knn_model.score(X_test_scaled, y_test))

            #  √âvaluation du mod√®le Random Forest
            rf_model.fit(X_train_scaled, y_train)
            list_rf_train.append(rf_model.score(X_train_scaled, y_train))
            list_rf_test.append(rf_model.score(X_test_scaled, y_test))

        #  Graphique pour KNN
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(list_knn_train, label="KNN Train", color='purple')
        ax.plot(list_knn_test, label="KNN Test", color="orange")
        ax.set_title("Performance du KNN")
        ax.legend()
        ax.set_xticks(range(len(importance_list)))
        ax.set_xticklabels(importance_list, rotation=80)
        st.pyplot(fig)

        #  Graphique pour Random Forest
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(list_rf_train, label="Random Forest Train", color='blue')
        ax.plot(list_rf_test, label="Random Forest Test", color="green")
        ax.set_title("Performance du Random Forest")
        ax.legend()
        ax.set_xticks(range(len(importance_list)))
        ax.set_xticklabels(importance_list, rotation=80)
        st.pyplot(fig)




    # üìå D√©finir le r√©pertoire des fichiers mod√®les
    save_dir = "etude3/"

    # üìå V√©rifier si les fichiers mod√®les existent
    model_files = ["KNN_smote.pkl", "RF_smote.pkl", "scaler.pkl", "features.pkl"]


    # üìå Charger les mod√®les et transformations
    knn = joblib.load(save_dir+ "KNN_smote.pkl")
    rforest = joblib.load(save_dir+  "RF_smote.pkl")
    scaler = joblib.load(save_dir+  "scaler.pkl")
    model_features = joblib.load(save_dir+  "features.pkl")
    

    # üìå Charger le dataset
    @st.cache_data
    def load_data():
        df = pd.read_csv("data_merge_v2.csv")

        # S√©lectionner les bonnes colonnes
        df2 = df[['cod_cbr','hybride','masse_ordma_min','masse_ordma_max',"puiss_max","W (mm)","At1 (mm)","At2 (mm)",'Carrosserie','typ_boite','nb_rapp','category']]

        # Encodage des variables cat√©goriques
        df2["hybride"] = df2["hybride"].replace({"non": 0, "oui": 1})
        df2["category"] = df2["category"].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})
        df2 = pd.get_dummies(df2)

        # S'assurer que toutes les features correspondent au mod√®le
        for feature in model_features:
            if feature not in df2.columns:
                df2[feature] = 0  # Ajouter les colonnes manquantes avec des valeurs nulles

        # R√©organiser les colonnes pour correspondre au mod√®le
        df2 = df2[["category"] + model_features]

        return df2

    df = load_data()

    # üìå S√©parer X et y
    X = df.drop(columns=["category"])
    y = df["category"]

    # üìå Split des donn√©es (m√™me split que lors de l'entra√Ænement)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)

    # üìå Appliquer le StandardScaler d√©j√† entra√Æn√©
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # üìå Calculer les scores sans refaire `fit()`
    knn_train_score = knn.score(X_train_scaled, y_train)  # Utiliser le scaler charg√©
    knn_test_score = knn.score(X_test_scaled, y_test)

    rf_train_score = rforest.score(X_train_scaled, y_train)
    rf_test_score = rforest.score(X_test_scaled, y_test)

    # üìå Afficher les r√©sultats dans Streamlit
    st.subheader("R√©sultats du Mod√®le KNN (Charg√©)")
    st.write(f"üîπ **Score d'entra√Ænement :** {knn_train_score:.3f}")
    st.write(f"üîπ **Score de test :** {knn_test_score:.3f}")

    st.subheader("R√©sultats du Mod√®le Random Forest (Charg√©)")
    st.write(f"üîπ **Score d'entra√Ænement :** {rf_train_score:.3f}")
    st.write(f"üîπ **Score de test :** {rf_test_score:.3f}")



    st.write('# Deep Learning')
    model = tf.keras.models.load_model('deep_learning/model.h5')
    st.title("Description du Mod√®le de Classification")

    st.markdown("""
    ### üìå **Architecture du mod√®le**
    Ce mod√®le de Deep Learning est un r√©seau de neurones **fully connected** con√ßu pour une classification en **7 cat√©gories**.

    - Il est constitu√© de **3 couches cach√©es** avec activation **ReLU**.
    - Il utilise des techniques de **Batch Normalization** et **Dropout** pour stabiliser l'entra√Ænement et √©viter l'overfitting.
    - La couche de sortie applique **Softmax** pour fournir des probabilit√©s de classification.

    ###  **Structure des couches**
    | **Type** | **Nombre de Neurones** | **Activation** | **R√¥le** |
    |----------|------------------|--------------|------------------------------|
    | **Entr√©e** | 34 (features) | - | Re√ßoit les donn√©es d'entr√©e |
    | **Cach√©e 1** | 128 | ReLU | Capture les patterns complexes |
    | | BatchNormalization | - | - | Stabilise et acc√©l√®re l'entra√Ænement |
    | | Dropout | - | - | R√©gularisation (√©vite l'overfitting) |
    | **Cach√©e 2** | 64 | ReLU | R√©duit la complexit√© et affine les patterns |
    | | BatchNormalization | - | - | Normalisation des activations |
    | | Dropout | - | - | R√©gularisation |
    | **Cach√©e 3** | 32 | ReLU | Capture des caract√©ristiques plus abstraites |
    | | BatchNormalization | - | - | Normalisation |
    | | Dropout | - | - | R√©gularisation |
    | **Sortie** | 7 | Softmax | Classification multiclasse |

    ### **D√©tails suppl√©mentaires**
    - **Optimiseur** : Adam (`learning_rate=0.001`)
    - **Fonction de perte** : Sparse Categorical Crossentropy
    - **Nombre total de param√®tres** : `15943`
    """)

    # Afficher un r√©sum√© d√©taill√© du mod√®le dans Streamlit
    st.subheader("R√©sum√© du mod√®le")
    

    # Charger le mod√®le et son historique d'entra√Ænement
    model = tf.keras.models.load_model('deep_learning/model.h5')

    # Charger l'historique de l'entra√Ænement (si sauvegard√©)
    try:
        history = joblib.load('deep_learning/history.pkl')
    except FileNotFoundError:
        st.error("Fichier d'historique non trouv√©. Assurez-vous d'avoir sauvegard√© history.")

    # V√©rifier si l'historique est charg√©
    if 'history' in locals():
        st.title("Analyse des Performances du Mod√®le")

        # Courbe d'accuracy
        st.subheader("√âvolution de la pr√©cision (accuracy)")
        fig, ax = plt.subplots()
        ax.plot(history['accuracy'], label='Train Accuracy', marker='o')
        ax.plot(history['val_accuracy'], label='Validation Accuracy', marker='o')
        ax.set_xlabel('Epochs')
        ax.set_ylabel('Accuracy')
        ax.legend()
        ax.grid()
        st.pyplot(fig)

        # Courbe de perte (loss)
        st.subheader("√âvolution de la perte (loss)")
        fig, ax = plt.subplots()
        ax.plot(history['loss'], label='Train Loss', marker='o', color='red')
        ax.plot(history['val_loss'], label='Validation Loss', marker='o', color='blue')
        ax.set_xlabel('Epochs')
        ax.set_ylabel('Loss')
        ax.legend()
        ax.grid()
        st.pyplot(fig)

        #st.success("Les performances du mod√®le ont √©t√© affich√©es avec succ√®s ! ‚úÖ")













    